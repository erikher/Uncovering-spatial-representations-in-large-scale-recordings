{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_new import *    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559abd3",
   "metadata": {},
   "source": [
    "Load data from Zong et al. (2022), mouse 97045 session 20210307"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203328d0",
   "metadata": {},
   "source": [
    "Preprocess data, cluster neurons and visualize statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b9213",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "\n",
    "data_dir = '/Users/erihe/OneDrive - NTNU/TDA_review/weijan'\n",
    "\n",
    "\n",
    "mouse = '97045'\n",
    "sessall = np.sort(glob.glob(data_dir + '/' + mouse + '/*'))\n",
    "for sess in sessall[2:3]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "    del filtered_events, nat_all, NeuronInformation\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr1 = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr1,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35979430",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi = 300)\n",
    "d2 = Xcorr1.copy()\n",
    "d2 = d2[np.argsort(ind1), :]\n",
    "d2 = d2[:,np.argsort(ind1)]    \n",
    "plt.imshow(d2, \n",
    "           vmin = np.percentile(d2.flatten(),5),\n",
    "           vmax = np.percentile(d2.flatten(),95),\n",
    "          )\n",
    "plt.axis('off')\n",
    "bin_ind = np.bincount(ind1)\n",
    "numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "print('num: ', bin_ind[numneuronsind[:10]])\n",
    "print('ind: ', numneuronsind[:10])\n",
    "\n",
    "plt.savefig('Figures/Zong_corrmat.png', transparent = True,  bbox_inches='tight', pad_inches=0.2)\n",
    "plt.savefig('Figures/Zong_corrmat.pdf', transparent = True, bbox_inches='tight', pad_inches=0.2)\n",
    "\n",
    "data = []\n",
    "data_names = []\n",
    "for i in range(len(d2)):\n",
    "    data.append(pd.Series(d2[:,i]))\n",
    "    data_names.extend(['col_' + str(i)])\n",
    "df = pd.concat(data, ignore_index=True, axis=1)            \n",
    "df.columns = data_names\n",
    "df.to_excel(\"Source_data/ExtFig1c_crossmat.xlsx\", sheet_name='crossmat')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39a64d",
   "metadata": {},
   "source": [
    "Fixate analysis on single cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8aee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==0)[0]\n",
    "print(len(mod_inds))\n",
    "\n",
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557885ec",
   "metadata": {},
   "source": [
    "Apply PCA to 6 dim and temporally downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea63b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 6\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c60b61",
   "metadata": {},
   "source": [
    "Compute the persistent homology of the downsampled neural ensemble activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e86e6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('n_points', n_points)\n",
    "indstemp = indstemp[:n_points]\n",
    "dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "thresh = np.max(d[~np.isinf(d)])    \n",
    "persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "print('movetimes1', len(movetimes1))\n",
    "n_points = len(indstemp)\n",
    "\n",
    "dgms = persistence['dgms']\n",
    "fig = plot_barcode(dgms)\n",
    "\n",
    "\n",
    "\n",
    "coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.plot(var_exp[:15], lw = 2.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "for i in range(len(coords_ds)):\n",
    "    ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "for i in range(3):\n",
    "    ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "for i in range(len(coords_ds_consistent)):\n",
    "    ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "for i in range(3):\n",
    "    ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700b94b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "ff1 = ['Zong',]\n",
    "for mouse_sess in ff1:\n",
    "    print(mouse_sess)\n",
    "    diagrams_roll = {}\n",
    "    count = -1\n",
    "    for i in range(0,101):\n",
    "        if i == 0:\n",
    "            f = np.load('Zong_dgms/dgms' + str(0) + '.npz', allow_pickle = True)\n",
    "            dgms_real = f['dgms'][()][0]\n",
    "            f.close()\n",
    "            continue\n",
    "        try :\n",
    "            f = np.load('Zong_dgms/dgms' + str(i) + '.npz', allow_pickle = True)\n",
    "            dgmstmp = f['dgms'][()]\n",
    "            f.close()\n",
    "            count += 1\n",
    "            diagrams_roll[count] = dgmstmp[0]\n",
    "        except:\n",
    "            continue\n",
    "    xmax = 1\n",
    "    print(count)\n",
    "    plot_barcode(dgms_real, diagrams_roll = diagrams_roll, percshuf = 99, dpi = 300, SaveSourceDataName = 'Zong_barcode')\n",
    "    plt.savefig('Figures/Zong_barcode.png', transparent = True,  bbox_inches='tight', pad_inches=0.2)\n",
    "    plt.savefig('Figures/Zong_barcode.pdf', transparent = True, bbox_inches='tight', pad_inches=0.2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ed138",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds_consistent,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 300)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 300)\n",
    "data = []\n",
    "data_names = []\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    for i in range(len(mtot)):\n",
    "        data.append(pd.Series(mtot[:,i]))\n",
    "        data_names.extend(['circ' +str(c) + 'col' + str(i)])\n",
    "    \n",
    "df = pd.concat(data, ignore_index=True, axis=1)            \n",
    "df.columns = data_names\n",
    "df.to_excel('Source_data/Fig1c_Zong_spaceVtorus.xlsx', sheet_name='Zong_spaceVtorus')  \n",
    "    \n",
    "fig2.savefig('Figures/Zong_spaceVtorus.png', transparent = True, bbox_inches='tight', pad_inches=0.2)\n",
    "fig2.savefig('Figures/Zong_spaceVtorus.pdf', transparent = True, bbox_inches='tight', pad_inches=0.2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed88dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = len(sspk2[0,:])\n",
    "\n",
    "numfigs = 2\n",
    "numw = 5\n",
    "numh = int(np.ceil(num_neurons/numw))\n",
    "outer1 = gridspec.GridSpec(1, numw)\n",
    "fig = plt.figure(figsize=(np.ceil((numw*numfigs+numw-1)*1.05), np.ceil(numh*1.1)), dpi = 120)\n",
    "plt.viridis()\n",
    "nw = 0\n",
    "sig1 = 1\n",
    "numbins1 = 30\n",
    "\n",
    "torsort = np.arange(num_neurons)#np.flip(np.argsort(pcorr))\n",
    "cc = coords_mod1.copy()\n",
    "\n",
    "for nn, n in enumerate(torsort):\n",
    "    nnn = nn%numh\n",
    "    if nnn == 0:\n",
    "        outer2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec = outer1[nw], wspace = .3)\n",
    "        gs2 = gridspec.GridSpecFromSubplotSpec(numh, numfigs, subplot_spec = outer2[0], hspace = 0.2,wspace = .0)\n",
    "        nw += 1\n",
    "    num_neurons = len(sspk2[0,:])\n",
    "\n",
    "    ax = plt.subplot(gs2[nnn,0]) \n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(xx1, yy1,\n",
    "                                  sspk2[:,n], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "    mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "    minval = 0 \n",
    "    maxval = np.percentile(mtot_tmp.flatten(), 97.5)\n",
    "    mtot_tmp[nans] = -np.inf\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', vmin = minval, vmax = maxval)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "    ax = plt.subplot(gs2[nnn,1]) \n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(cc[:,0], cc[:,1],\n",
    "                                          sspk2[:,n], statistic='mean', \n",
    "                                         bins=numbins1, range=None, expand_binnumbers=True)\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    mtot_tmp = smooth_tuning_map(np.rot90(mtot_tmp,1), numbins1+1, sig1, bClose = True) \n",
    "    minval = 0 \n",
    "    maxval = np.percentile(mtot_tmp.flatten(), 97.5)\n",
    "    mtot_tmp[nans] = -np.inf\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', extent = [0,2*np.pi,0, 2*np.pi], \n",
    "              vmin = minval, vmax = maxval)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1/ax.get_data_ratio())\n",
    "    r_box = transforms.Affine2D().skew_deg(15,15)\n",
    "    for x in ax.images + ax.lines + ax.collections:\n",
    "        trans = x.get_transform()\n",
    "        x.set_transform(r_box+trans) \n",
    "        if isinstance(x, PathCollection):\n",
    "            transoff = x.get_offset_transform()\n",
    "            x._transOffset = r_box+transoff     \n",
    "    ax.set_xlim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_ylim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_aspect('equal', 'box') \n",
    "    ax.axis('off')   \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = len(sspk2[0,:])\n",
    "torsort = np.arange(num_neurons)#np.flip(np.argsort(pcorr))\n",
    "\n",
    "curr_inds = np.concatenate((np.argsort(torsort)[22:25], np.argsort(torsort)[6:9]))\n",
    "num_neurons = len(curr_inds)\n",
    "\n",
    "numfigs = 2\n",
    "numw = 2\n",
    "numh = int(np.ceil(num_neurons/numw))\n",
    "outer1 = gridspec.GridSpec(1, numw)\n",
    "fig = plt.figure(figsize=(np.ceil((numw*numfigs+numw-1)*1.05), np.ceil(numh*1.1)), dpi = 300)\n",
    "plt.viridis()\n",
    "nw = 0\n",
    "sig1 = 1\n",
    "numbins1 = 30\n",
    "\n",
    "#torsort = np.arange(num_neurons)#np.flip(np.argsort(pcorr))\n",
    "cc = coords_mod1.copy()\n",
    "\n",
    "data = []\n",
    "data_names = []\n",
    "for nn, n in enumerate(curr_inds):\n",
    "    nnn = nn%numh\n",
    "    if nnn == 0:\n",
    "        outer2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec = outer1[nw], wspace = .3)\n",
    "        gs2 = gridspec.GridSpecFromSubplotSpec(numh, numfigs, subplot_spec = outer2[0], hspace = 0.2,wspace = .0)\n",
    "        nw += 1\n",
    "    num_neurons = len(sspk2[0,:])\n",
    "\n",
    "    ax = plt.subplot(gs2[nnn,0]) \n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(xx1, yy1,\n",
    "                                  sspk2[:,n], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "    mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "    minval = 0 \n",
    "    maxval = np.percentile(mtot_tmp.flatten(), 97.5)\n",
    "    mtot_tmp[nans] = -np.inf\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', vmin = minval, vmax = maxval)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    for i in range(len(mtot_tmp)):\n",
    "        data.append(pd.Series(mtot_tmp[:,i]))\n",
    "        data_names.extend(['space' + str(i)])\n",
    "\n",
    "\n",
    "\n",
    "    ax = plt.subplot(gs2[nnn,1]) \n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(cc[:,0], cc[:,1],\n",
    "                                          sspk2[:,n], statistic='mean', \n",
    "                                         bins=numbins1, range=None, expand_binnumbers=True)\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    mtot_tmp = smooth_tuning_map(np.rot90(mtot_tmp,1), numbins1+1, sig1, bClose = True) \n",
    "    minval = 0 \n",
    "    maxval = np.percentile(mtot_tmp.flatten(), 97.5)\n",
    "    mtot_tmp[nans] = -np.inf\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', extent = [0,2*np.pi,0, 2*np.pi], \n",
    "              vmin = minval, vmax = maxval)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1/ax.get_data_ratio())\n",
    "    r_box = transforms.Affine2D().skew_deg(15,15)\n",
    "    for x in ax.images + ax.lines + ax.collections:\n",
    "        trans = x.get_transform()\n",
    "        x.set_transform(r_box+trans) \n",
    "        if isinstance(x, PathCollection):\n",
    "            transoff = x.get_offset_transform()\n",
    "            x._transOffset = r_box+transoff     \n",
    "    ax.set_xlim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_ylim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_aspect('equal', 'box') \n",
    "    ax.axis('off')   \n",
    "\n",
    "    for i in range(len(mtot_tmp)):\n",
    "        data.append(pd.Series(mtot_tmp[:,i]))\n",
    "        data_names.extend(['torus' + str(i)])\n",
    "    \n",
    "    df = pd.concat(data, ignore_index=True, axis=1)            \n",
    "    df.columns = data_names\n",
    "    df.to_excel('Source_data/ExtFig1c_Zong_single_tuning' + str(nn) + '.xlsx', sheet_name='Zong_single_tuning' + str(nn))  \n",
    "plt.savefig('Figures/Zong_single_tuning.png', transparent = True, bbox_inches='tight', pad_inches=0.2)\n",
    "plt.savefig('Figures/Zong_single_tuning.pdf', transparent = True, bbox_inches='tight', pad_inches=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
