{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bcafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir1 = '/Users/erihe/OneDrive - NTNU/'\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "from utils_new import *\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d4fb3",
   "metadata": {},
   "source": [
    "## 94557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232fd59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse = '94557'\n",
    "sessall = glob.glob(data_dir + '/' + mouse + '/*')\n",
    "for sess in sessall[:1]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "    sspk1 = sspk1[movetimes0,:]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[:,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[:,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2)\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.77\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b787c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_neurons = len(sspk1[0,:])\n",
    "rmap = np.zeros((num_neurons, 25, 25))\n",
    "acorr = np.zeros((num_neurons, 25, 25))\n",
    "numbins1 = 25\n",
    "sig1 = 1\n",
    "\n",
    "for i in range(num_neurons):\n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                              sspk1[movetimes0,i], statistic='mean', \n",
    "                             bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "    mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "    acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "    rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "hd_info = np.zeros(num_neurons)\n",
    "for i in range(num_neurons):\n",
    "    mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "    mu = np.mean(sspk1[:,i])\n",
    "    hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "for i in rel_inds:\n",
    "    mod_ind1s = np.where(ind1==i)[0]\n",
    "    if len(mod_ind1s)>=2:\n",
    "        print('Mod ', i)\n",
    "        print('num_neurons ', len(mod_ind1s))\n",
    "        print(mod_ind1s)\n",
    "        sspk2 = sspk1[:,mod_ind1s]\n",
    "        sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "        scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                       num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba25028",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b42ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==10)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954c188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0))[0]\n",
    "sspk2 = sspk2[movetimes0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1200\n",
    "dim = 6\n",
    "eps = 0.2\n",
    "k = 1000\n",
    "spk1 = preprocessing.scale(sspk2,axis = 0)\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(spk1, dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])                        \n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, metric = 'euclidean', \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb4838a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1200,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             spk2 = sspk2,\n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "plt.hsv()\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = headdirection[movetimes0]/360*2*np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfa1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = coords_mod1[:,1].copy()\n",
    "dc = np.arctan2(np.mean(np.sin(cc- hd)), np.mean(np.cos(cc- hd)))%(2*np.pi)\n",
    "cc -= dc \n",
    "cc = cc%(2*np.pi)\n",
    "print(np.mean(np.abs(np.arctan2(np.sin(cc- hd), np.cos(cc- hd)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cc[:1000])\n",
    "plt.plot(hd[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4233ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09a464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5766cf1",
   "metadata": {},
   "source": [
    "## 100072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83edc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse = '100072'\n",
    "sessall = glob.glob(data_dir + '/' + mouse + '/*')\n",
    "for sess in sessall[:1]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2)\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.8\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df74c37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_neurons = len(sspk1[0,:])\n",
    "rmap = np.zeros((num_neurons, 25, 25))\n",
    "acorr = np.zeros((num_neurons, 25, 25))\n",
    "numbins1 = 25\n",
    "sig1 = 1\n",
    "\n",
    "for i in range(num_neurons):\n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[:,0], headpos[:,1],\n",
    "                              sspk1[:,i], statistic='mean', \n",
    "                             bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "    mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "    acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "    rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "hd_info = np.zeros(num_neurons)\n",
    "for i in range(num_neurons):\n",
    "    mtot, __, circ = binned_statistic(headdirection[:], sspk1[:,i], statistic = 'mean', bins = 30)\n",
    "    mu = np.mean(sspk1[:,i])\n",
    "    hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "for i in rel_inds:\n",
    "    mod_ind1s = np.where(ind1==i)[0]\n",
    "    if len(mod_ind1s)>=2:\n",
    "        print('Mod ', i)\n",
    "        print('num_neurons ', len(mod_ind1s))\n",
    "        print(mod_ind1s)\n",
    "        sspk2 = sspk1[:,mod_ind1s]\n",
    "        sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "        scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                       num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c656b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==3)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97cb98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1200\n",
    "dim = 7\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, metric = 'euclidean', \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da63211",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1200,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8955d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             spk2 = sspk2,\n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "plt.hsv()\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = headdirection[movetimes0]/360*2*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1065ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = coords_mod1[:,1].copy()\n",
    "dc = np.arctan2(np.mean(np.sin(cc- hd)), np.mean(np.cos(cc- hd)))%(2*np.pi)\n",
    "cc -= dc \n",
    "cc = cc%(2*np.pi)\n",
    "print(np.mean(np.abs(np.arctan2(np.sin(cc- hd), np.cos(cc- hd)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe52fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cc[:1000])\n",
    "plt.plot(hd[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9dc40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4267f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ead93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a38e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "403a69e0",
   "metadata": {},
   "source": [
    "## 97045"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce7aa7b",
   "metadata": {},
   "source": [
    "## 20210305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688ee05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse = '97045'\n",
    "sessall = glob.glob(data_dir + '/' + mouse + '/*')\n",
    "for sess in sessall[:1]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba94c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.92\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29060ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38dd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==0)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438d00c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 7\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac6ff7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1600,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1465f14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1300,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191dfc08",
   "metadata": {},
   "source": [
    "## 20210307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971b9213",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse = '97045'\n",
    "sessall = np.sort(glob.glob(data_dir + '/' + mouse + '/*'))\n",
    "for sess in sessall[2:3]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "    del filtered_events, nat_all, NeuronInformation\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr1 = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr1,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.nn.functional import relu\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PairwiseDistance \n",
    "import torch.nn as nn\n",
    "import torch.fft\n",
    "\n",
    "from torch_topological.nn import SummaryStatisticLoss\n",
    "from torch_topological.nn import VietorisRipsComplex\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class Ensembler(torch.nn.Module):\n",
    "    def __init__(self, N, batch_size, maxdim, meshstart, meshstop, num_in_mesh,  \n",
    "                 init_weights = [], seed=42, normalize_columns=False):\n",
    "        super(Ensembler, self).__init__()\n",
    "        self.normalize_columns = normalize_columns\n",
    "        torch.manual_seed(seed)\n",
    "        if len(init_weights) == 0:\n",
    "            self.weights = torch.nn.Parameter(\n",
    "              torch.randn(N, N),\n",
    "              requires_grad=True)\n",
    "        else:\n",
    "            self.weights = torch.nn.Parameter(\n",
    "              init_weights,\n",
    "              requires_grad=True)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        weights = torch.nn.functional.softmax(self.weights, dim=1)\n",
    "        mask = (weights == weights.max(dim=0, keepdim=True)[0])\n",
    "        weights = weights * mask\n",
    "        out = torch.matmul(weights, x)\n",
    "        return out, weights\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "class BettiCurves(nn.Module):\n",
    "    \"\"\"\n",
    "    Produces the Betti curve of the diagram\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    meshstart: The lowest value at which to begin the curve\n",
    "    meshstop: the highest value at which to stop the curve\n",
    "    num_in_mesh: The number of evenly spaced points between meshstart and meshstop at which to compute the curve values\n",
    "\n",
    "    Output:\n",
    "    num_in_mesh dimensional vector of Betti curve values computed at num_in_mesh evenly spaced points starting at meshstart and ending at meshstop\n",
    "    \"\"\"\n",
    "    def __init__(self, meshstart = 0, meshstop = 10, num_in_mesh = 1000, theta = 1000):\n",
    "        super(BettiCurves, self).__init__()\n",
    "        self.meshstart = meshstart\n",
    "        self.meshstop = meshstop\n",
    "        self.num_in_mesh = num_in_mesh\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, dgminfo):\n",
    "        \"\"\" Betti PersLay \"\"\"\n",
    "        sp = torch.from_numpy(np.linspace(self.meshstart,self.meshstop,self.num_in_mesh)).repeat(len(dgminfo)).reshape(len(dgminfo),self.num_in_mesh).T\n",
    "        return torch.sum(torch.sigmoid( 1e-6 + self.theta * (.5*(dgminfo[:,1]-dgminfo[:,0]) - torch.abs(sp - .5*(dgminfo[:,1]+dgminfo[:,0])))),1)\n",
    "\n",
    "\n",
    "\n",
    "def from_ripser_to_giotto(dgm, infmax= np.inf):\n",
    "    dgm_ret = []\n",
    "    for dim, i in enumerate(dgm):\n",
    "        i[np.isinf(i)] = infmax\n",
    "        for j in i:\n",
    "            dgm_ret.append([j[0],j[1], dim])\n",
    "    return dgm_ret\n",
    "\n",
    "class Teddy:\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_matrix,  # neurons x time steps\n",
    "            maxdim=2,  # optimize the first signature[1] H_signature[0]s\n",
    "            batch_size= 16,\n",
    "            meshstart = 0, \n",
    "            meshstop = 100, \n",
    "            num_in_mesh = 1000,\n",
    "            epochs=3,\n",
    "            train_steps=10,  # per epoch\n",
    "            lr=1e-2,\n",
    "            seed=47,\n",
    "            verbose=True,  # whether to print and plot intermediate statistics\n",
    "            device=\"cpu\",\n",
    "            num_worse=5,  # how many epochs loss may get worse before stopping\n",
    "            power=0.1,  # power in topological loss\n",
    "            normalize_columns=False,\n",
    "            save_file='teddy_weights',\n",
    "            init_weights = [],\n",
    "            numits = 1\n",
    "    ):\n",
    "        # Parameters\n",
    "        self.T,self.N  = data_matrix.shape\n",
    "        self.maxdim = maxdim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.train_steps = train_steps\n",
    "        self.lr = lr\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.num_worse = num_worse\n",
    "        self.power = power\n",
    "        self.save_file = save_file\n",
    "        self.betti_met = PairwiseDistance(metric='betti')\n",
    "        self.meshstart = meshstart\n",
    "        self.meshstop = meshstop\n",
    "        self.num_in_mesh = num_in_mesh\n",
    "        self.numits = numits\n",
    "        # Setup Data, Model, Optimizer\n",
    "        self.data_torch = torch.tensor(\n",
    "            data_matrix, dtype=torch.float).to(device)\n",
    "        self.rips = VietorisRipsComplex(dim=maxdim, p = 1).to(device)\n",
    "        \n",
    "        self.betti = BettiCurves(meshstart, meshstop, num_in_mesh).to(device)\n",
    "\n",
    "        self.model = Ensembler(self.N, batch_size, maxdim, meshstart, \n",
    "                               meshstop, num_in_mesh,init_weights).to(device)\n",
    "        self.optimizer = torch.optim.Adam([self.model.weights], lr=lr)\n",
    "        self.weights = []\n",
    "        self.Bs = []\n",
    "        self.Bs1 = []\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        worse = 0  # counter for early stopping\n",
    "        running_loss = 0.0\n",
    "        running_loss_top = 0.0\n",
    "        running_loss_rest = 0.0\n",
    "        run_loss, run_weights = [], []\n",
    "        run_Bs = []\n",
    "        run_Bs1 = []\n",
    "        t0 = time.time()\n",
    "        self.stats = {'loss_top': [], 'loss_rest': [], 'loss': []}\n",
    "        sp = torch.from_numpy(np.linspace(self.meshstart,self.meshstop,self.num_in_mesh))+1\n",
    "        for i in range(self.epochs * self.train_steps + 1):\n",
    "            # training step\n",
    "            self.optimizer.zero_grad()\n",
    "            Bs = torch.zeros(self.maxdim+1, self.num_in_mesh)\n",
    "            Bs1 = torch.zeros(self.maxdim+1, self.num_in_mesh)\n",
    "            l0 = torch.zeros(self.maxdim+1)\n",
    "            l00 = torch.zeros(self.maxdim+1)\n",
    "            for j in range(self.numits):\n",
    "                np.random.seed(self.seed + i*self.numits + j)\n",
    "                batch_ind = np.random.choice(self.T, self.batch_size, replace=False)\n",
    "                out, weights = self.model(self.data_torch[batch_ind, :].T)\n",
    "                out = torch.nn.functional.normalize(out,dim = 0, p = 1)\n",
    "                #out = torchvision.transforms.Normalize(out)\n",
    "                layer_out = self.rips(out.T + 1e-3)                  \n",
    "                layer_out1 = self.rips(out + 1e-3)\n",
    "                \n",
    "                for d in range(self.maxdim+1):\n",
    "                    lives0 = layer_out[d][1][:,1] - layer_out[d][1][:,0]\n",
    "                    l0[d] += len(lives0)\n",
    "                    lives00 = layer_out1[d][1][:,1] - layer_out1[d][1][:,0]\n",
    "                    l00[d] += len(lives00)\n",
    "                    if l0[d] > 0:\n",
    "                        Bs1[d] += self.betti(layer_out[d][1][lives0>0,:])*sp*(l0[d]+l00[d])/(2*l0[d])#/max(1,len(lives0[lives0>0]))*sp\n",
    "                    if l00[d] > 0:\n",
    "                        Bs[d] += self.betti(layer_out1[d][1][lives00>0,:])*sp*(l0[d]+l00[d])/(2*l00[d])#/max(1,len(lives0[lives0>0]))*sp\n",
    "\n",
    "#            loss = torch.sum(torch.pow((Bs-Bs1),2))                   \n",
    "            print('loss', loss)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.lr)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # logging\n",
    "            run_loss.append(loss.item())\n",
    "            run_weights.append(self.model.weights.detach().cpu().numpy().copy())\n",
    "            run_Bs.append([B0.cpu().detach().numpy() for B0 in Bs])\n",
    "            run_Bs1.append([B0.cpu().detach().numpy() for B0 in Bs1])\n",
    "            if i > -1 and not (i % self.train_steps):\n",
    "                # early stopping\n",
    "                run_best = np.argmin(run_loss)\n",
    "                self.stats['loss'].append(run_loss[run_best])\n",
    "                self.weights.append(run_weights[run_best])\n",
    "                self.Bs.append(run_Bs[run_best])\n",
    "                self.Bs1.append(run_Bs1[run_best])\n",
    "                if self.verbose:\n",
    "                    log = 'run=%s, time=%.2fs' % (i, time.time() - t0)\n",
    "                    print(log)\n",
    "                    self.plotting(run_weights[run_best], self.stats['loss'],  run_Bs[run_best], run_Bs1[run_best])\n",
    "                if i > 0:\n",
    "                    if self.stats['loss'][-1] > self.stats['loss'][-2]:\n",
    "                        worse += 1\n",
    "                        if worse > self.num_worse:\n",
    "                            print('Early stopping at iteration', i)\n",
    "                            break\n",
    "                    else:\n",
    "                        worse = 0 \n",
    "                run_loss, run_weights, run_Bs, run_Bs1 = [], [], [], []\n",
    "        print('Training finished.')\n",
    "\n",
    "\n",
    "    def plotting(self, weights, run_loss, Bs, Bs1):\n",
    "        xs = np.linspace(self.meshstart, self.meshstop, self.num_in_mesh)\n",
    "        plt.figure()\n",
    "        for d in range(self.maxdim+1):\n",
    "            plt.plot(xs, Bs[d], c = ['k', 'r','g'][d])\n",
    "        plt.figure()\n",
    "        for d in range(self.maxdim+1):\n",
    "            plt.plot(xs, Bs1[d], c = ['k', 'r','g'][d])\n",
    "        \n",
    "        plt.figure(figsize=(18, 3))        \n",
    "        plt.subplot(1,3, 1)  # complete weight matrix\n",
    "        plt.imshow(weights, vmin = np.percentile(weights.flatten(),2.5), \n",
    "                   vmax = np.percentile(weights.flatten(),97.5),)\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.subplot(1, 3, 2)  # max over columns of weight matrix\n",
    "        ax1 = plt.gca()\n",
    "        ax2 = ax1.twinx()\n",
    "        ax1.plot(weights.max(0), 'g-')\n",
    "        ax1.set_xlabel('weights')\n",
    "        ax1.set_ylabel('max over columns', color='g', alpha=.5)\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(run_loss, '.-', label='loss')\n",
    "        plt.title('loss')\n",
    "\n",
    "        print(run_loss)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.nn.functional import relu\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PairwiseDistance \n",
    "import torch.nn as nn\n",
    "import torch.fft\n",
    "from torch_topological.nn import SummaryStatisticLoss\n",
    "from torch_topological.nn import VietorisRipsComplex\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class Ensembler(torch.nn.Module):\n",
    "    def __init__(self, N, batch_size, maxdim, meshstart, meshstop, num_in_mesh,  \n",
    "                 init_weights = [], seed=42, normalize_columns=False):\n",
    "        super(Ensembler, self).__init__()\n",
    "        self.normalize_columns = normalize_columns\n",
    "        torch.manual_seed(seed)\n",
    "        if len(init_weights) == 0:\n",
    "            self.weights = torch.nn.Parameter(\n",
    "              torch.randn(N, N),\n",
    "              requires_grad=True)\n",
    "        else:\n",
    "            self.weights = torch.nn.Parameter(\n",
    "              init_weights,\n",
    "              requires_grad=True)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        weights = torch.nn.functional.softmax(self.weights, dim=1)\n",
    "        mask = (weights == weights.max(dim=0, keepdim=True)[0])\n",
    "        weights = weights * mask\n",
    "        out = torch.matmul(weights, x)\n",
    "        return out, weights\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "class BettiCurves(nn.Module):\n",
    "    \"\"\"\n",
    "    Produces the Betti curve of the diagram\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    meshstart: The lowest value at which to begin the curve\n",
    "    meshstop: the highest value at which to stop the curve\n",
    "    num_in_mesh: The number of evenly spaced points between meshstart and meshstop at which to compute the curve values\n",
    "\n",
    "    Output:\n",
    "    num_in_mesh dimensional vector of Betti curve values computed at num_in_mesh evenly spaced points starting at meshstart and ending at meshstop\n",
    "    \"\"\"\n",
    "    def __init__(self, meshstart = 0, meshstop = 10, num_in_mesh = 1000, theta = 1000):\n",
    "        super(BettiCurves, self).__init__()\n",
    "        self.meshstart = meshstart\n",
    "        self.meshstop = meshstop\n",
    "        self.num_in_mesh = num_in_mesh\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, dgminfo):\n",
    "        \"\"\" Betti PersLay \"\"\"\n",
    "        sp = torch.from_numpy(np.linspace(self.meshstart,self.meshstop,self.num_in_mesh)).repeat(len(dgminfo)).reshape(len(dgminfo),self.num_in_mesh).T\n",
    "        return torch.sum(torch.sigmoid( 1e-6 + self.theta * (.5*(dgminfo[:,1]-dgminfo[:,0]) - torch.abs(sp - .5*(dgminfo[:,1]+dgminfo[:,0])))),1)\n",
    "\n",
    "\n",
    "\n",
    "def from_ripser_to_giotto(dgm, infmax= np.inf):\n",
    "    dgm_ret = []\n",
    "    for dim, i in enumerate(dgm):\n",
    "        i[np.isinf(i)] = infmax\n",
    "        for j in i:\n",
    "            dgm_ret.append([j[0],j[1], dim])\n",
    "    return dgm_ret\n",
    "\n",
    "class Teddy:\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_matrix,  # neurons x time steps\n",
    "            maxdim=2,  # optimize the first signature[1] H_signature[0]s\n",
    "            batch_size= 16,\n",
    "            meshstart = 0, \n",
    "            meshstop = 100, \n",
    "            num_in_mesh = 1000,\n",
    "            epochs=3,\n",
    "            train_steps=10,  # per epoch\n",
    "            lr=1e-2,\n",
    "            seed=47,\n",
    "            verbose=True,  # whether to print and plot intermediate statistics\n",
    "            device=\"cpu\",\n",
    "            num_worse=5,  # how many epochs loss may get worse before stopping\n",
    "            power=0.1,  # power in topological loss\n",
    "            normalize_columns=False,\n",
    "            save_file='teddy_weights',\n",
    "            init_weights = [],\n",
    "            numits = 1\n",
    "    ):\n",
    "        # Parameters\n",
    "        self.T,self.N  = data_matrix.shape\n",
    "        self.maxdim = maxdim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.train_steps = train_steps\n",
    "        self.lr = lr\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.num_worse = num_worse\n",
    "        self.power = power\n",
    "        self.save_file = save_file\n",
    "        self.betti_met = PairwiseDistance(metric='betti')\n",
    "        self.meshstart = meshstart\n",
    "        self.meshstop = meshstop\n",
    "        self.num_in_mesh = num_in_mesh\n",
    "        self.numits = numits\n",
    "        # Setup Data, Model, Optimizer\n",
    "        self.data_torch = torch.tensor(\n",
    "            data_matrix, dtype=torch.float).to(device)\n",
    "        self.rips = VietorisRipsComplex(dim=maxdim, p = 1).to(device)\n",
    "        \n",
    "        self.betti = BettiCurves(meshstart, meshstop, num_in_mesh).to(device)\n",
    "\n",
    "        self.model = Ensembler(self.N, batch_size, maxdim, meshstart, \n",
    "                               meshstop, num_in_mesh,init_weights).to(device)\n",
    "        self.optimizer = torch.optim.Adam([self.model.weights], lr=lr)\n",
    "        self.weights = []\n",
    "        self.Bs = []\n",
    "        self.Bs1 = []\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        worse = 0  # counter for early stopping\n",
    "        running_loss = 0.0\n",
    "        running_loss_top = 0.0\n",
    "        running_loss_rest = 0.0\n",
    "        run_loss, run_weights = [], []\n",
    "        run_Bs = []\n",
    "        run_Bs1 = []\n",
    "        t0 = time.time()\n",
    "        self.stats = {'loss_top': [], 'loss_rest': [], 'loss': []}\n",
    "        sp = torch.from_numpy(np.linspace(self.meshstart,self.meshstop,self.num_in_mesh))+1\n",
    "        for i in range(self.epochs * self.train_steps + 1):\n",
    "            # training step\n",
    "            self.optimizer.zero_grad()\n",
    "            Bs = torch.zeros(self.maxdim+1, self.num_in_mesh)\n",
    "            Bs1 = torch.zeros(self.maxdim+1, self.num_in_mesh)\n",
    "            l0 = torch.zeros(self.maxdim+1)\n",
    "            l00 = torch.zeros(self.maxdim+1)\n",
    "            for j in range(self.numits):\n",
    "                np.random.seed(self.seed + i*self.numits + j)\n",
    "                batch_ind = np.random.choice(self.T, self.batch_size, replace=False)\n",
    "                out, weights = self.model(self.data_torch[batch_ind, :].T)\n",
    "                out = torch.nn.functional.normalize(out,dim = 0, p =2 )\n",
    "                layer_out = self.rips(out.T + 1e-3)                  \n",
    "                \n",
    "                for d in range(self.maxdim+1):\n",
    "                    lives0 = layer_out[d][1][:,1] - layer_out[d][1][:,0]\n",
    "                    l0[d] += len(lives0)\n",
    "                    if l0[d] > 0:\n",
    "                        Bs[d] += self.betti(layer_out[d][1][lives0>0,:])\n",
    "            loss = -torch.sum(torch.diff(lives0)*lives0[1:])#/torch.sum(Bs)\n",
    "            \n",
    "            print('loss', loss)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.lr)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # logging\n",
    "            run_loss.append(loss.item())\n",
    "            run_weights.append(self.model.weights.detach().cpu().numpy().copy())\n",
    "            run_Bs.append([B0.cpu().detach().numpy() for B0 in Bs])\n",
    "            run_Bs1.append([B0.cpu().detach().numpy() for B0 in Bs1])\n",
    "            if i > -1 and not (i % self.train_steps):\n",
    "                # early stopping\n",
    "                run_best = np.argmin(run_loss)\n",
    "                self.stats['loss'].append(run_loss[run_best])\n",
    "                self.weights.append(run_weights[run_best])\n",
    "                self.Bs.append(run_Bs[run_best])\n",
    "                self.Bs1.append(run_Bs1[run_best])\n",
    "                if self.verbose:\n",
    "                    log = 'run=%s, time=%.2fs' % (i, time.time() - t0)\n",
    "                    print(log)\n",
    "                    self.plotting(run_weights[run_best], self.stats['loss'],  run_Bs[run_best], run_Bs1[run_best])\n",
    "                if i > 0:\n",
    "                    if self.stats['loss'][-1] > self.stats['loss'][-2]:\n",
    "                        worse += 1\n",
    "                        if worse > self.num_worse:\n",
    "                            print('Early stopping at iteration', i)\n",
    "                            break\n",
    "                    else:\n",
    "                        worse = 0 \n",
    "                run_loss, run_weights, run_Bs, run_Bs1 = [], [], [], []\n",
    "        print('Training finished.')\n",
    "\n",
    "\n",
    "    def plotting(self, weights, run_loss, Bs, Bs1):\n",
    "        xs = np.linspace(self.meshstart, self.meshstop, self.num_in_mesh)\n",
    "        plt.figure()\n",
    "        for d in range(self.maxdim+1):\n",
    "            plt.plot(xs, Bs[d], c = ['k', 'r','g'][d])\n",
    "        plt.figure()\n",
    "        for d in range(self.maxdim+1):\n",
    "            plt.plot(xs, Bs1[d], c = ['k', 'r','g'][d])\n",
    "        \n",
    "        plt.figure(figsize=(18, 3))        \n",
    "        plt.subplot(1,3, 1)  # complete weight matrix\n",
    "        plt.imshow(weights, vmin = np.percentile(weights.flatten(),2.5), \n",
    "                   vmax = np.percentile(weights.flatten(),97.5),)\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.subplot(1, 3, 2)  # max over columns of weight matrix\n",
    "        ax1 = plt.gca()\n",
    "        ax2 = ax1.twinx()\n",
    "        ax1.plot(weights.max(0), 'g-')\n",
    "        ax1.set_xlabel('weights')\n",
    "        ax1.set_ylabel('max over columns', color='g', alpha=.5)\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(run_loss, '.-', label='loss')\n",
    "        plt.title('loss')\n",
    "\n",
    "        print(run_loss)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651839e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xcorr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662816bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.nn.functional import relu\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PairwiseDistance \n",
    "import torch.nn as nn\n",
    "import torch.fft\n",
    "from torch_topological.nn import SummaryStatisticLoss\n",
    "from torch_topological.nn import VietorisRipsComplex\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class Ensembler(torch.nn.Module):\n",
    "    def __init__(self, N, batch_size, maxdim, meshstart, meshstop, num_in_mesh,  \n",
    "                 init_weights = [], seed=42, normalize_columns=False):\n",
    "        super(Ensembler, self).__init__()\n",
    "        self.normalize_columns = normalize_columns\n",
    "        torch.manual_seed(seed)\n",
    "        if len(init_weights) == 0:\n",
    "            self.weights = torch.nn.Parameter(\n",
    "              torch.randn(N, N),\n",
    "              requires_grad=True)\n",
    "        else:\n",
    "            self.weights = torch.nn.Parameter(\n",
    "              init_weights,\n",
    "              requires_grad=True)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        weights = torch.nn.functional.softmax(self.weights, dim=1)\n",
    "        mask = (weights == weights.max(dim=0, keepdim=True)[0])\n",
    "        weights = weights * mask\n",
    "        out = torch.matmul(weights, x)\n",
    "        return out, weights\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "class BettiCurves(nn.Module):\n",
    "    \"\"\"\n",
    "    Produces the Betti curve of the diagram\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    meshstart: The lowest value at which to begin the curve\n",
    "    meshstop: the highest value at which to stop the curve\n",
    "    num_in_mesh: The number of evenly spaced points between meshstart and meshstop at which to compute the curve values\n",
    "\n",
    "    Output:\n",
    "    num_in_mesh dimensional vector of Betti curve values computed at num_in_mesh evenly spaced points starting at meshstart and ending at meshstop\n",
    "    \"\"\"\n",
    "    def __init__(self, meshstart = 0, meshstop = 10, num_in_mesh = 1000, theta = 1000):\n",
    "        super(BettiCurves, self).__init__()\n",
    "        self.meshstart = meshstart\n",
    "        self.meshstop = meshstop\n",
    "        self.num_in_mesh = num_in_mesh\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, dgminfo):\n",
    "        \"\"\" Betti PersLay \"\"\"\n",
    "        sp = torch.from_numpy(np.linspace(self.meshstart,self.meshstop,self.num_in_mesh)).repeat(len(dgminfo)).reshape(len(dgminfo),self.num_in_mesh).T\n",
    "        return torch.sum(torch.sigmoid( 1e-6 + self.theta * (.5*(dgminfo[:,1]-dgminfo[:,0]) - torch.abs(sp - .5*(dgminfo[:,1]+dgminfo[:,0])))),1)\n",
    "\n",
    "\n",
    "\n",
    "def from_ripser_to_giotto(dgm, infmax= np.inf):\n",
    "    dgm_ret = []\n",
    "    for dim, i in enumerate(dgm):\n",
    "        i[np.isinf(i)] = infmax\n",
    "        for j in i:\n",
    "            dgm_ret.append([j[0],j[1], dim])\n",
    "    return dgm_ret\n",
    "\n",
    "class Teddy:\n",
    "    def __init__(\n",
    "            self,\n",
    "            data_matrix,  # neurons x time steps\n",
    "            maxdim=2,  # optimize the first signature[1] H_signature[0]s\n",
    "            batch_size= 16,\n",
    "            meshstart = 0, \n",
    "            meshstop = 100, \n",
    "            num_in_mesh = 1000,\n",
    "            epochs=3,\n",
    "            train_steps=10,  # per epoch\n",
    "            lr=1e-2,\n",
    "            seed=47,\n",
    "            verbose=True,  # whether to print and plot intermediate statistics\n",
    "            device=\"cpu\",\n",
    "            num_worse=5,  # how many epochs loss may get worse before stopping\n",
    "            power=0.1,  # power in topological loss\n",
    "            normalize_columns=False,\n",
    "            save_file='teddy_weights',\n",
    "            init_weights = [],\n",
    "            numits = 1\n",
    "    ):\n",
    "        # Parameters\n",
    "        self.T,self.N  = data_matrix.shape\n",
    "        self.maxdim = maxdim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.train_steps = train_steps\n",
    "        self.lr = lr\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.num_worse = num_worse\n",
    "        self.power = power\n",
    "        self.save_file = save_file\n",
    "        self.betti_met = PairwiseDistance(metric='betti')\n",
    "        self.meshstart = meshstart\n",
    "        self.meshstop = meshstop\n",
    "        self.num_in_mesh = num_in_mesh\n",
    "        self.numits = numits\n",
    "        # Setup Data, Model, Optimizer\n",
    "        self.data_torch = torch.tensor(\n",
    "            data_matrix, dtype=torch.float).to(device)\n",
    "        self.rips = VietorisRipsComplex(dim=maxdim, p = 1).to(device)\n",
    "        \n",
    "        self.betti = BettiCurves(meshstart, meshstop, num_in_mesh).to(device)\n",
    "\n",
    "        self.model = Ensembler(self.N, batch_size, maxdim, meshstart, \n",
    "                               meshstop, num_in_mesh,init_weights).to(device)\n",
    "        self.optimizer = torch.optim.Adam([self.model.weights], lr=lr)\n",
    "        self.weights = []\n",
    "        self.Bs = []\n",
    "        self.Bs1 = []\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        worse = 0  # counter for early stopping\n",
    "        running_loss = 0.0\n",
    "        running_loss_top = 0.0\n",
    "        running_loss_rest = 0.0\n",
    "        run_loss, run_weights = [], []\n",
    "        run_Bs = []\n",
    "        run_Bs1 = []\n",
    "        t0 = time.time()\n",
    "        self.stats = {'loss_top': [], 'loss_rest': [], 'loss': []}\n",
    "        sp = torch.from_numpy(np.linspace(self.meshstart,self.meshstop,self.num_in_mesh))+1\n",
    "        for i in range(self.epochs * self.train_steps + 1):\n",
    "            # training step\n",
    "            self.optimizer.zero_grad()\n",
    "            Bs = torch.zeros(self.maxdim+1, self.num_in_mesh)\n",
    "            Bs1 = torch.zeros(self.maxdim+1, self.num_in_mesh)\n",
    "            l0 = torch.zeros(self.maxdim+1)\n",
    "            l00 = torch.zeros(self.maxdim+1)\n",
    "            for j in range(self.numits):\n",
    "                np.random.seed(self.seed + i*self.numits + j)\n",
    "                batch_ind = np.random.choice(self.T, self.batch_size, replace=False)\n",
    "                out, weights = self.model(self.data_torch[batch_ind, :].T)\n",
    "                print(out.shape)\n",
    "                out = torch.nn.functional.normalize(out,dim = 0, p =2 ).T\n",
    "                layer_out = self.rips(out + 1e-3)     \n",
    "                for d in range(self.maxdim+1):\n",
    "                    lives0 = layer_out[d][1][:,1] - layer_out[d][1][:,0]\n",
    "                    l0[d] += len(lives0)\n",
    "                    if l0[d] > 0:\n",
    "                        Bs[d] += self.betti(layer_out[d][1][lives0>0,:])\n",
    "                        if d == 0:\n",
    "                            sortdist = torch.sort(torch.cdist(out, out),1).values\n",
    "                            outfirst = torch.tensor(torch.concatenate((torch.zeros(len(out),1),\n",
    "                                                                       sortdist[:, 1:2]),1))\n",
    "                            Bs[d] -= self.betti(outfirst)\n",
    "\n",
    "            #print(torch.sigmoid(torch.diff(lives0)))\n",
    "#            print(lives0, torch.diff(lives0))\n",
    "#            print(torch.mean(Bs*sp), torch.sum(torch.diff(lives0)*lives0[1:])*len(lives0))\n",
    "#            loss = torch.mean(Bs*sp)-torch.sum(torch.diff(lives0)*lives0[1:])*len(lives0)\n",
    "#            print(torch.diff(lives0))\n",
    "#            loss = -torch.sum(torch.diff(lives0)*lives0[1:])/torch.sum(Bs)\n",
    "            loss = -torch.sum(Bs)\n",
    "            \n",
    "            print('loss', loss)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.lr)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # logging\n",
    "            run_loss.append(loss.item())\n",
    "            run_weights.append(self.model.weights.detach().cpu().numpy().copy())\n",
    "            run_Bs.append([B0.cpu().detach().numpy() for B0 in Bs])\n",
    "            run_Bs1.append([B0.cpu().detach().numpy() for B0 in Bs1])\n",
    "            if i > -1 and not (i % self.train_steps):\n",
    "                # early stopping\n",
    "                run_best = np.argmin(run_loss)\n",
    "                self.stats['loss'].append(run_loss[run_best])\n",
    "                self.weights.append(run_weights[run_best])\n",
    "                self.Bs.append(run_Bs[run_best])\n",
    "                self.Bs1.append(run_Bs1[run_best])\n",
    "                if self.verbose:\n",
    "                    log = 'run=%s, time=%.2fs' % (i, time.time() - t0)\n",
    "                    print(log)\n",
    "                    self.plotting(run_weights[run_best], self.stats['loss'],  run_Bs[run_best], run_Bs1[run_best])\n",
    "                if i > 0:\n",
    "                    if self.stats['loss'][-1] > self.stats['loss'][-2]:\n",
    "                        worse += 1\n",
    "                        if worse > self.num_worse:\n",
    "                            print('Early stopping at iteration', i)\n",
    "                            break\n",
    "                    else:\n",
    "                        worse = 0 \n",
    "                run_loss, run_weights, run_Bs, run_Bs1 = [], [], [], []\n",
    "        print('Training finished.')\n",
    "\n",
    "\n",
    "    def plotting(self, weights, run_loss, Bs, Bs1):\n",
    "        xs = np.linspace(self.meshstart, self.meshstop, self.num_in_mesh)\n",
    "        plt.figure()\n",
    "        for d in range(self.maxdim+1):\n",
    "            plt.plot(xs, Bs[d], c = ['k', 'r','g'][d])\n",
    "        plt.figure()\n",
    "        for d in range(self.maxdim+1):\n",
    "            plt.plot(xs, Bs1[d], c = ['k', 'r','g'][d])\n",
    "        \n",
    "        plt.figure(figsize=(18, 3))        \n",
    "        plt.subplot(1,3, 1)  # complete weight matrix\n",
    "        plt.imshow(weights, vmin = np.percentile(weights.flatten(),2.5), \n",
    "                   vmax = np.percentile(weights.flatten(),97.5),)\n",
    "        plt.colorbar()\n",
    "\n",
    "        plt.subplot(1, 3, 2)  # max over columns of weight matrix\n",
    "        ax1 = plt.gca()\n",
    "        ax2 = ax1.twinx()\n",
    "        ax1.plot(weights.max(0), 'g-')\n",
    "        ax1.set_xlabel('weights')\n",
    "        ax1.set_ylabel('max over columns', color='g', alpha=.5)\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(run_loss, '.-', label='loss')\n",
    "        plt.title('loss')\n",
    "\n",
    "        print(run_loss)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749469b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#xc = xc[:, indssort_bu<3000][:, indssort_bu1<2000]\n",
    "model = Teddy( preprocessing.scale(sspk1,axis = 0),\n",
    "            maxdim = 0,\n",
    "            batch_size = 150,\n",
    "            epochs = 100,\n",
    "            train_steps = 100,\n",
    "            meshstart = 0, \n",
    "            meshstop = 10, \n",
    "            num_in_mesh = 1000,            \n",
    "            lr = 0.001,\n",
    "            num_worse = 10,\n",
    "            numits = 1,\n",
    "#            init_weights = torch.tensor(model.weights[-1])\n",
    "            )\n",
    "model.train()\n",
    "indssort = np.sum(model.weights,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e3c215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a33b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "indssort = np.max(model.weights[np.argmin(model.stats['loss'])],0)\n",
    "plt.plot(indssort)\n",
    "#plt.plot(indssort1)\n",
    "plt.plot(np.sort(indssort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc254715",
   "metadata": {},
   "outputs": [],
   "source": [
    "indssort = np.sum(model.weights[np.argmin(model.stats['loss'])],0)\n",
    "plt.plot(indssort)\n",
    "#plt.plot(indssort1)\n",
    "plt.plot(np.sort(indssort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4934984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtmp = Xcorr[:, indssort_bu<3000].copy()\n",
    "#xtmp = xtmp[indssort_bu<3000, :]\n",
    "#xtmp = xtmp[:, indssort_bu1<2000].copy()\n",
    "#xtmp = xtmp[indssort_bu1<2000, :]\n",
    "xtmp = Xcorr.copy() \n",
    "\n",
    "plt.imshow(xtmp, vmin = np.percentile(xtmp.flatten(), 2.5), vmax = np.percentile(xtmp.flatten(), 97.5))\n",
    "plt.show()\n",
    "xtmp = xtmp[np.argsort(indssort),:]\n",
    "xtmp = xtmp[:, np.argsort(indssort)]\n",
    "plt.imshow(xtmp, vmin = np.percentile(xtmp.flatten(), 2.5), vmax = np.percentile(xtmp.flatten(), 97.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtmp = Xcorr1[:, indssort_bu<3000].copy()\n",
    "#xtmp = xtmp[indssort_bu<3000, :]\n",
    "#xtmp = xtmp[:, indssort_bu1<2000].copy()\n",
    "#xtmp = xtmp[indssort_bu1<2000, :]\n",
    "xtmp = Xcorr1.copy()\n",
    "plt.imshow(xtmp, vmin = np.percentile(xtmp.flatten(), 2.5), vmax = np.percentile(xtmp.flatten(), 97.5))\n",
    "plt.show()\n",
    "xtmp = xtmp[np.argsort(indssort),:]\n",
    "xtmp = xtmp[:, np.argsort(indssort)]\n",
    "plt.imshow(xtmp, vmin = np.percentile(xtmp.flatten(), 2.5), vmax = np.percentile(xtmp.flatten(), 97.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ffd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hd_info, indssort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.sum(sspk1>0,0), indssort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5327c0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in np.argsort(indssort)[:30]:\n",
    "    plt.figure()\n",
    "    plt.imshow(rmap[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9cdd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in np.argsort(indssort)[-30:]:\n",
    "    plt.figure()\n",
    "    plt.imshow(rmap[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtmp = Xcorr1.copy()\n",
    "\n",
    "plt.imshow(xtmp, vmin = np.percentile(xtmp.flatten(), 2.5), vmax = np.percentile(xtmp.flatten(), 97.5))\n",
    "plt.show()\n",
    "xtmp = xtmp[np.argsort(indssort),:]\n",
    "xtmp = xtmp[:, np.argsort(indssort)]\n",
    "plt.imshow(xtmp, vmin = np.percentile(xtmp.flatten(), 2.5), vmax = np.percentile(xtmp.flatten(), 97.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f372d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtmp = Xcorr.copy()\n",
    "\n",
    "plt.imshow(xtmp, vmin = np.percentile(xtmp.flatten(), 2.5), vmax = np.percentile(xtmp.flatten(), 97.5))\n",
    "plt.show()\n",
    "xtmp = xtmp[np.argsort(indssort),:]\n",
    "xtmp = xtmp[:, np.argsort(indssort)]\n",
    "plt.imshow(xtmp, vmin = np.percentile(xtmp.flatten(), 2.5), vmax = np.percentile(xtmp.flatten(), 97.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd897f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hd_info, indssort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(indssort>3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f015d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "its = len(model.weights)\n",
    "rangeits = np.arange(0,its,4)\n",
    "plt.figure(figsize = (10,5), dpi = 120)\n",
    "for i in rangeits:\n",
    "    plt.plot(np.max(model.weights[i],0), label = str(i), c = cm.viridis(i/its))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0beb47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "its = len(model.Bs)\n",
    "range_its = np.arange(its)\n",
    "plt.figure(figsize = (10,5), dpi = 120)\n",
    "for i in range_its:\n",
    "    plt.plot(model.Bs[i][0], label = str(i), c = cm.viridis(i/its))\n",
    "    print(i, np.sum(model.Bs[i][0]))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize = (10,5), dpi = 120)\n",
    "for i in range_its:\n",
    "    plt.plot(model.Bs[i][1], label = str(i), c = cm.viridis(i/its))\n",
    "    print(i, np.sum(model.Bs[i][1]))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,5), dpi = 120)\n",
    "for i in range_its:\n",
    "    plt.plot(model.Bs[i][2], label = str(i), c = cm.viridis(i/its))\n",
    "    print(i, np.sum(model.Bs[i][2]))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1a598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5313179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Zong_data', sspikes_of1 = sspk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35979430",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr1,thr, linkage = 'average', bPlot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==0)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8aee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea63b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 6\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e86e6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [n_points,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ed138",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds_consistent,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed88dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = len(sspk2[0,:])\n",
    "\n",
    "numfigs = 2\n",
    "numw = 5\n",
    "numh = int(np.ceil(num_neurons/numw))\n",
    "outer1 = gridspec.GridSpec(1, numw)\n",
    "fig = plt.figure(figsize=(np.ceil((numw*numfigs+numw-1)*1.05), np.ceil(numh*1.1)), dpi = 120)\n",
    "plt.viridis()\n",
    "nw = 0\n",
    "sig1 = 1\n",
    "numbins1 = 30\n",
    "\n",
    "torsort = np.arange(num_neurons)#np.flip(np.argsort(pcorr))\n",
    "cc = coords_mod1.copy()\n",
    "\n",
    "for nn, n in enumerate(torsort):\n",
    "    nnn = nn%numh\n",
    "    if nnn == 0:\n",
    "        outer2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec = outer1[nw], wspace = .3)\n",
    "        gs2 = gridspec.GridSpecFromSubplotSpec(numh, numfigs, subplot_spec = outer2[0], hspace = 0.2,wspace = .0)\n",
    "        nw += 1\n",
    "    num_neurons = len(sspk2[0,:])\n",
    "\n",
    "    ax = plt.subplot(gs2[nnn,0]) \n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(xx1, yy1,\n",
    "                                  sspk2[:,n], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "    mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "    minval = 0 \n",
    "    maxval = np.percentile(mtot_tmp.flatten(), 97.5)\n",
    "    mtot_tmp[nans] = -np.inf\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', vmin = minval, vmax = maxval)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "    ax = plt.subplot(gs2[nnn,1]) \n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(cc[:,0], cc[:,1],\n",
    "                                          sspk2[:,n], statistic='mean', \n",
    "                                         bins=numbins1, range=None, expand_binnumbers=True)\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    mtot_tmp = smooth_tuning_map(np.rot90(mtot_tmp,1), numbins1+1, sig1, bClose = True) \n",
    "    minval = 0 \n",
    "    maxval = np.percentile(mtot_tmp.flatten(), 97.5)\n",
    "    mtot_tmp[nans] = -np.inf\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', extent = [0,2*np.pi,0, 2*np.pi], \n",
    "              vmin = minval, vmax = maxval)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1/ax.get_data_ratio())\n",
    "    r_box = transforms.Affine2D().skew_deg(15,15)\n",
    "    for x in ax.images + ax.lines + ax.collections:\n",
    "        trans = x.get_transform()\n",
    "        x.set_transform(r_box+trans) \n",
    "        if isinstance(x, PathCollection):\n",
    "            transoff = x.get_offset_transform()\n",
    "            x._transOffset = r_box+transoff     \n",
    "    ax.set_xlim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_ylim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_aspect('equal', 'box') \n",
    "    ax.axis('off')   \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc67169",
   "metadata": {},
   "source": [
    "## 20210308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d69c439",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse = '97045'\n",
    "sessall = glob.glob(data_dir + '/' + mouse + '/*')\n",
    "for sess in sessall[3:4]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daffce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.92\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e556be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a57d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==1)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c91da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 6\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu,\n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518d822",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1600,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a0559",
   "metadata": {},
   "source": [
    "## 20210314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e8510",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse = '97045'\n",
    "sessall = glob.glob(data_dir + '/' + mouse + '/*')\n",
    "for sess in sessall[4:5]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.92\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3843a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==0)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76577e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901bf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 4\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc42a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1600,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017810f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [700,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b52bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e44c73",
   "metadata": {},
   "source": [
    "## 20210317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da84dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse = '97045'\n",
    "sessall = glob.glob(data_dir + '/' + mouse + '/*')\n",
    "for sess in sessall[5:]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.87\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff174d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa64832",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==0)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f249889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ee09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 6\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129bc96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1600,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2170c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa796fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ec582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1643a503",
   "metadata": {},
   "source": [
    "## 97046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse = '97046'\n",
    "sessall = glob.glob(data_dir + '/' + mouse + '/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a0e2b",
   "metadata": {},
   "source": [
    "## 20210307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5dbb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "for sess in sessall[:1]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579396fd",
   "metadata": {},
   "source": [
    "## 20210308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff173b90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "for sess in sessall[1:2]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517397c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds = np.where((bin_ind>=30) & (bin_ind<=650))[0]                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==1)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dfe9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 6\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d4494",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1600,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72273c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d5903",
   "metadata": {},
   "source": [
    "## 20210309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ecad1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "for sess in sessall[2:3]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d36728",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==0)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45508cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b19f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 6\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b68f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1600,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e7bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa8dfc",
   "metadata": {},
   "source": [
    "## 20210312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad209cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "for sess in sessall[3:4]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.87\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa41c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36769ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93749b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==4)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c9b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 6\n",
    "eps = 0.5\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba05350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1600,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea55a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec88f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a12f0c6",
   "metadata": {},
   "source": [
    "## 20210313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149432a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "for sess in sessall[4:5]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1455f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.86\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb9845d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea78db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==0)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842fd6ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a070af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 4\n",
    "eps = 0.3\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afca905",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1600,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46521481",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [800,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70711689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83abb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_red_spikes_move_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581990ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = 600 \n",
    "metric = 'cosine'\n",
    "X = squareform(pdist(dim_red_spikes_move_scaled[:,:], metric))\n",
    "knn_indices = np.argsort(X)[:, :nbs]\n",
    "knn_dists = X[np.arange(X.shape[0])[:, None], knn_indices].copy()\n",
    "sigmas, rhos = smooth_knn_dist(knn_dists, nbs, local_connectivity=0)\n",
    "rows, cols, vals = compute_membership_strengths(knn_indices, knn_dists, sigmas, rhos)\n",
    "result = coo_matrix((vals, (rows, cols)), shape=(X.shape[0], X.shape[0]))\n",
    "result.eliminate_zeros()\n",
    "transpose = result.transpose()\n",
    "prod_matrix = result.multiply(transpose)\n",
    "result = (result + transpose - prod_matrix)\n",
    "result.eliminate_zeros()\n",
    "d = result.toarray()\n",
    "d = -np.log(d)\n",
    "np.fill_diagonal(d,0)\n",
    "thresh = np.max(d[~np.isinf(d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ef295",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc = ComplexProjectiveCoords(d, n_landmarks= min(400, len(X)), distance_matrix=True)\n",
    "fig = plt.figure()\n",
    "\n",
    "plot_diagrams(cpc.dgms_, lifetime=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f7fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = cpc.get_coordinates(perc=0.99, proj_dim=1, cocycle_idx=0, standard_range = False ,projective_dim_red_mode='one-by-one')\n",
    "coords_R3 = ProjectiveMapUtils.hopf_map(coords)\n",
    "coords_R2 = ProjectiveMapUtils.stereographic_projection_hemispheres(coords_R3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c09f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.axis(\"off\")\n",
    "_ = PlotUtils.plot_2sphere_boundary()\n",
    "plt.scatter(coords_R2[:,0], coords_R2[:,1],c=dim_red_spikes_move_scaled[:,1])\n",
    "_ = plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hsv()\n",
    "plt.scatter(xx1[indstemp], yy1[indstemp], c = coords_R2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = headdirection[movetimes0]/360*2*np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ddc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = coords_mod1[:,0].copy()\n",
    "dc = np.arctan2(np.mean(np.sin(cc- hd)), np.mean(np.cos(cc- hd)))%(2*np.pi)\n",
    "cc -= dc \n",
    "cc = cc%(2*np.pi)\n",
    "print(np.mean(np.abs(np.arctan2(np.sin(cc- hd), np.cos(cc- hd)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cc[:1000])\n",
    "plt.plot(hd[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa939ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b2f5f57",
   "metadata": {},
   "source": [
    "## 20210313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ba675",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "for sess in sessall[5:]:\n",
    "    print(sess)    \n",
    "    NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    headdirection = headdirection[1:-1]\n",
    "    speed = speed[1:-1]\n",
    "\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "    try:\n",
    "        NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    except:\n",
    "        NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "        if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "            repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "    sig0  = 2\n",
    "    sspk1 = sspikes[:,indssort]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "    sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "    lenc = 10                \n",
    "    lenspk, num_neurons = np.shape(sspk1)           \n",
    "    Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "    Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "    np.fill_diagonal(Xcorr,0)\n",
    "    Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "    thr = 0.85\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "    movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "\n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    rmap = np.zeros((num_neurons, 25, 25))\n",
    "    acorr = np.zeros((num_neurons, 25, 25))\n",
    "    numbins1 = 25\n",
    "    sig1 = 1\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[movetimes0,i], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "        nans = np.isnan(mtot_tmp)\n",
    "        mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "        mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "        acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "        rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "    hd_info = np.zeros(num_neurons)\n",
    "    for i in range(num_neurons):\n",
    "        mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[movetimes0,i], statistic = 'mean', bins = 30)\n",
    "        mu = np.mean(sspk1[:,i])\n",
    "        hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "    scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eec317",
   "metadata": {},
   "outputs": [],
   "source": [
    "    thr = 0.83\n",
    "    ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "    bin_ind = np.bincount(ind1)\n",
    "    numneuronsind = np.flip(np.argsort(bin_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56465361",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "    for i in rel_inds:\n",
    "        mod_ind1s = np.where(ind1==i)[0]\n",
    "        if len(mod_ind1s)>=2:\n",
    "            print('Mod ', i)\n",
    "            print('num_neurons ', len(mod_ind1s))\n",
    "            print(mod_ind1s)\n",
    "            sspk2 = sspk1[:,mod_ind1s]\n",
    "            sspk2 = preprocessing.scale(sspk2[movetimes0])\n",
    "\n",
    "            scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                           num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462bab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7cf727",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==0)[0]\n",
    "print(len(mod_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34c040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0) & (speed>5))[0]\n",
    "sspk2 = sspk2[movetimes0,:]\n",
    "print(np.shape(sspk2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30173dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1600\n",
    "dim = 5\n",
    "eps = 0.4\n",
    "k = 1000\n",
    "\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(preprocessing.scale(sspk2,axis = 0), dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])      \n",
    "\n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c36d3a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1200,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7644bea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [800,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coords_mod1 = get_coords_all(sspk2, \n",
    "                             coords_ds,\n",
    "                             np.arange(len(sspk2)),                             \n",
    "                             indstemp,\n",
    "                             dim = dim, \n",
    "                             bPCA = True,\n",
    "                             bPred = False)\n",
    "\n",
    "\n",
    "xx1 = headpos[movetimes0,0]\n",
    "yy1 = headpos[movetimes0,1]\n",
    "sig = 1\n",
    "fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "fig2, axs2 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "for c in [0,1,]:\n",
    "    plt.hsv()\n",
    "    axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "    axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "    axs1[c].axis('off')\n",
    "    \n",
    "\n",
    "    nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "    mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                              headpos[movetimes0,1][nans0],\n",
    "                                              coords_mod1[:,c][nans0], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,sig)\n",
    "    costot = gaussian_filter(costot,sig)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    plt.viridis()\n",
    "    axs2[c].imshow(mtot)\n",
    "    axs2[c].axis('off')\n",
    "    axs2[c].set_aspect(1/axs2[c].get_data_ratio())\n",
    "\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = 600 \n",
    "metric = 'euclidean'\n",
    "X = squareform(pdist(dim_red_spikes_move_scaled[:,:], metric))\n",
    "knn_indices = np.argsort(X)[:, :nbs]\n",
    "knn_dists = X[np.arange(X.shape[0])[:, None], knn_indices].copy()\n",
    "sigmas, rhos = smooth_knn_dist(knn_dists, nbs, local_connectivity=0)\n",
    "rows, cols, vals = compute_membership_strengths(knn_indices, knn_dists, sigmas, rhos)\n",
    "result = coo_matrix((vals, (rows, cols)), shape=(X.shape[0], X.shape[0]))\n",
    "result.eliminate_zeros()\n",
    "transpose = result.transpose()\n",
    "prod_matrix = result.multiply(transpose)\n",
    "result = (result + transpose - prod_matrix)\n",
    "result.eliminate_zeros()\n",
    "d = result.toarray()\n",
    "d = -np.log(d)\n",
    "np.fill_diagonal(d,0)\n",
    "thresh = np.max(d[~np.isinf(d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3fc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc = ComplexProjectiveCoords(d, n_landmarks= min(400, len(X)), distance_matrix=True)\n",
    "fig = plt.figure()\n",
    "\n",
    "plot_diagrams(cpc.dgms_, lifetime=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = cpc.get_coordinates(perc=0.9, proj_dim=1, cocycle_idx=0, standard_range = False ,projective_dim_red_mode='one-by-one')\n",
    "coords_R3 = ProjectiveMapUtils.hopf_map(coords)\n",
    "coords_R2 = ProjectiveMapUtils.stereographic_projection_hemispheres(coords_R3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad213b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.axis(\"off\")\n",
    "_ = PlotUtils.plot_2sphere_boundary()\n",
    "plt.scatter(coords_R2[:,0], coords_R2[:,1],c=dim_red_spikes_move_scaled[:,1])\n",
    "_ = plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hsv()\n",
    "plt.scatter(xx1[indstemp], yy1[indstemp], c = coords_R2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = headdirection[movetimes0]/360*2*np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = coords_mod1[:,0].copy()\n",
    "dc = np.arctan2(np.mean(np.sin(cc- hd)), np.mean(np.cos(cc- hd)))%(2*np.pi)\n",
    "cc -= dc \n",
    "cc = cc%(2*np.pi)\n",
    "print(np.mean(np.abs(np.arctan2(np.sin(cc- hd), np.cos(cc- hd)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cc[:1000])\n",
    "plt.plot(hd[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75962e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7083769",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f39e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fd6927b",
   "metadata": {},
   "source": [
    "## Climb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17fc7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for mouse in mouse_all[-1:]:\n",
    "    sessall = glob.glob(data_dir + '/' + mouse + '/*')\n",
    "    for sess in sessall[:1]:\n",
    "        print(sess)    \n",
    "        NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "        nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "        filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "        tt = nat_all[0,:]\n",
    "        headpos = nat_all[1:3,:].T\n",
    "        headdirection = nat_all[3,:]    \n",
    "        speed = nat_all[4,:]\n",
    "\n",
    "        sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "        for i in range(len(filtered_events)):\n",
    "            if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "                continue\n",
    "            if np.isnan(filtered_events[i,0]):\n",
    "                sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "            else:\n",
    "                sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "        sspikes = sspikes[1:-1,:]\n",
    "        tt = tt[1:-1]\n",
    "        headpos = headpos[1:-1,:]\n",
    "        speed = speed[1:-1]\n",
    "\n",
    "        repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "        try:\n",
    "            NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "            if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "                repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "        except:\n",
    "            NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "            if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "                repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "        sspikes = sspikes[:, repremove]\n",
    "        sspikes[np.isnan(sspikes)] = 0\n",
    "        sspikes[sspikes<0.001] = 0\n",
    "        spksum = np.mean(sspikes,0)\n",
    "        indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "        sig0  = 2\n",
    "        sspk1 = sspikes[:,indssort]\n",
    "        sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "        sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "        lenc = 10                \n",
    "        lenspk, num_neurons = np.shape(sspk1)           \n",
    "        Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "        Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "        np.fill_diagonal(Xcorr,0)\n",
    "        Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "        thr = 0.85\n",
    "        ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "        bin_ind = np.bincount(ind1)\n",
    "        numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "        movetimes0 = np.where((np.sum(sspk1,1)>0))[0]\n",
    "        sspk1 = sspk1[movetimes0,:]\n",
    "\n",
    "        num_neurons = len(sspk1[0,:])\n",
    "        rmap = np.zeros((num_neurons, 25, 25))\n",
    "        acorr = np.zeros((num_neurons, 25, 25))\n",
    "        numbins1 = 25\n",
    "        sig1 = 1\n",
    "\n",
    "        for i in range(num_neurons):\n",
    "            mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                      sspk1[:,i], statistic='mean', \n",
    "                                     bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "            nans = np.isnan(mtot_tmp)\n",
    "            mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "            mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "            acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "            rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "        hd_info = np.zeros(num_neurons)\n",
    "        for i in range(num_neurons):\n",
    "            mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[:,i], statistic = 'mean', bins = 30)\n",
    "            mu = np.mean(sspk1[:,i])\n",
    "            hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "        scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "        rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "        for i in rel_inds:\n",
    "            mod_ind1s = np.where(ind1==i)[0]\n",
    "            if len(mod_ind1s)>=2:\n",
    "                print('Mod ', i)\n",
    "                print('num_neurons ', len(mod_ind1s))\n",
    "                print(mod_ind1s)\n",
    "                sspk2 = sspk1[:,mod_ind1s]\n",
    "                sspk2 = preprocessing.scale(sspk2)\n",
    "\n",
    "                scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                               num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        thr = 0.91\n",
    "        ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "        bin_ind = np.bincount(ind1)\n",
    "        numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "headdirection = headdirection[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        sig0  = 2\n",
    "        sspk1 = sspikes[:,indssort]\n",
    "        spknull0 = sspk1.sum(0)>0\n",
    "        sspk1 = sspk1[:, spknull0 ]\n",
    "        sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "        sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "        movetimes0 = np.where((np.sum(sspk1,1)>0))[0]\n",
    "        sspk1 = sspk1[movetimes0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c8cc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "        num_neurons = len(sspk1[0,:])\n",
    "        rmap = np.zeros((num_neurons, 25, 25))\n",
    "        acorr = np.zeros((num_neurons, 25, 25))\n",
    "        numbins1 = 25\n",
    "        sig1 = 1\n",
    "\n",
    "        for i in range(num_neurons):\n",
    "            mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[:,0], headpos[:,1],\n",
    "                                      sspk1[:,i], statistic='mean', \n",
    "                                     bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "            nans = np.isnan(mtot_tmp)\n",
    "            mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "            mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "            acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "            rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "        hd_info = np.zeros(num_neurons)\n",
    "        for i in range(num_neurons):\n",
    "            mtot, __, circ = binned_statistic(headdirection[:], sspk1[:,i], statistic = 'mean', bins = 30)\n",
    "            mu = np.mean(sspk1[:,i])\n",
    "            hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "        scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "        rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "        for i in rel_inds:\n",
    "            mod_ind1s = np.where(ind1==i)[0]\n",
    "            if len(mod_ind1s)>=2:\n",
    "                print('Mod ', i)\n",
    "                print('num_neurons ', len(mod_ind1s))\n",
    "                print(mod_ind1s)\n",
    "                sspk2 = sspk1[:,mod_ind1s]\n",
    "                sspk2 = preprocessing.scale(sspk2)\n",
    "\n",
    "                scores_cluster(sspk2, scores,  mod_ind1s,headpos[:,0], headpos[:, 1], spk2 = [], \n",
    "                               num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd7696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_inds = np.where(ind1==3)[0]\n",
    "print(len(mod_inds))\n",
    "sig0  = 2\n",
    "sspk2 = sspikes[:,indssort]\n",
    "spknull0 = sspk2.sum(0)>0\n",
    "sspk2 = sspk2[:, spknull0 ]\n",
    "sspk2 = sspk2[:, mod_inds]\n",
    "sspk2 = preprocessing.minmax_scale(sspk2, axis = 0)\n",
    "\n",
    "sspk2 = np.sqrt(gaussian_filter1d(sspk2, axis = 0, sigma = sig0))\n",
    "movetimes0 = np.where((np.sum(sspk2,1)>0))[0]\n",
    "sspk2 = sspk2[movetimes0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1200\n",
    "dim = 6\n",
    "eps = 0.2\n",
    "k = 1000\n",
    "spk1 = preprocessing.scale(sspk2,axis = 0)\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(spk1, dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])                        \n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, metric = 'euclidean', \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed95f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [700,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    dgms = persistence['dgms']\n",
    "    fig = plot_barcode(dgms)\n",
    "    \n",
    "    \n",
    "    \n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cd6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "422ccec2",
   "metadata": {},
   "source": [
    "# Visual cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711da81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xy_all = {}\n",
    "movetimes_all = {}\n",
    "spk_all = {}\n",
    "coords_all = {}\n",
    "data_dir = 'weijan'\n",
    "mouse_all = ['99725']\n",
    "for mouse in mouse_all:\n",
    "    sessall = glob.glob(data_dir + '/' + mouse + '/*')\n",
    "    for sess in sessall:\n",
    "        if (mouse == '97045') & (sess[-8:] in ('20210305','20210306','20210307', '20210308')):\n",
    "                continue\n",
    "        print(sess)    \n",
    "        NAT = h5py.File(sess + '/' + 'NAT.mat')\n",
    "        nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "\n",
    "        filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "        tt = nat_all[0,:]\n",
    "        headpos = nat_all[1:3,:].T\n",
    "        headdirection = nat_all[3,:]    \n",
    "        speed = nat_all[4,:]\n",
    "\n",
    "        sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "        for i in range(len(filtered_events)):\n",
    "            if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "                continue\n",
    "            if np.isnan(filtered_events[i,0]):\n",
    "                sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "            else:\n",
    "                sspikes[1:-1,i] = scipy.interpolate.interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "        sspikes = sspikes[1:-1,:]\n",
    "        tt = tt[1:-1]\n",
    "        headpos = headpos[1:-1,:]\n",
    "        speed = speed[1:-1]\n",
    "\n",
    "        repremove = np.ones(len(sspikes[0,:]), dtype = bool)        \n",
    "        try:\n",
    "            NeuronInformation = sio.loadmat(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "            if len(NeuronInformation['RepeatCell'][()][0,0])>0:\n",
    "                repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "        except:\n",
    "            NeuronInformation = h5py.File(sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "            if len(NeuronInformation['RepeatCell'][()])>0:\n",
    "                repremove[NeuronInformation['RepeatCell'][()][0].astype(int)-1] = False\n",
    "\n",
    "        sspikes = sspikes[:, repremove]\n",
    "        sspikes[np.isnan(sspikes)] = 0\n",
    "        sspikes[sspikes<0.001] = 0\n",
    "        spksum = np.mean(sspikes,0)\n",
    "        indssort = np.where((spksum>0) & (spksum<10))[0]\n",
    "\n",
    "        sig0  = 2\n",
    "        sspk1 = sspikes[:,indssort]\n",
    "        spknull0 = sspk1.sum(0)>0\n",
    "        sspk1 = sspk1[:, spknull0 ]\n",
    "        sspk1 = preprocessing.minmax_scale(sspk1, axis = 0)\n",
    "        sspk1 = np.sqrt(gaussian_filter1d(sspk1, axis = 0, sigma = sig0))\n",
    "\n",
    "        lenc = 10                \n",
    "        lenspk, num_neurons = np.shape(sspk1)           \n",
    "        Xcorr = cross_corr_dist(sspk1, lencorr = lenc)\n",
    "        Xcorr[np.isnan(Xcorr)] = 1\n",
    "\n",
    "        np.fill_diagonal(Xcorr,0)\n",
    "        Xcorr = squareform(pdist(np.square(Xcorr), 'correlation'))\n",
    "\n",
    "        thr = 0.8\n",
    "        ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "        bin_ind = np.bincount(ind1)\n",
    "        numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n",
    "\n",
    "        movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "        sspk1 = sspk1[movetimes0,:]\n",
    "\n",
    "        num_neurons = len(sspk1[0,:])\n",
    "        rmap = np.zeros((num_neurons, 25, 25))\n",
    "        acorr = np.zeros((num_neurons, 25, 25))\n",
    "        numbins1 = 25\n",
    "        sig1 = 1\n",
    "\n",
    "        for i in range(num_neurons):\n",
    "            mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                      sspk1[:,i], statistic='mean', \n",
    "                                     bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "            nans = np.isnan(mtot_tmp)\n",
    "            mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "            mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "            acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "            rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "        hd_info = np.zeros(num_neurons)\n",
    "        for i in range(num_neurons):\n",
    "            mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[:,i], statistic = 'mean', bins = 30)\n",
    "            mu = np.mean(sspk1[:,i])\n",
    "            hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "        scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "        rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "        for i in rel_inds:\n",
    "            mod_ind1s = np.where(ind1==i)[0]\n",
    "            if len(mod_ind1s)>=2:\n",
    "                print('Mod ', i)\n",
    "                print('num_neurons ', len(mod_ind1s))\n",
    "                print(mod_ind1s)\n",
    "                sspk2 = sspk1[:,mod_ind1s]\n",
    "                sspk2 = preprocessing.scale(sspk2)\n",
    "\n",
    "                scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                               num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movetimes0 = np.where((speed>5) & (np.sum(sspk1,1)>0))[0]\n",
    "sspk1 = sspk1[movetimes0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thr = 0.92\n",
    "ind1 = get_ind(Xcorr,thr, linkage = 'average', bPlot = True)\n",
    "bin_ind = np.bincount(ind1)\n",
    "numneuronsind = np.flip(np.argsort(bin_ind))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755bda1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_neurons = len(sspk1[0,:])\n",
    "rmap = np.zeros((num_neurons, 25, 25))\n",
    "acorr = np.zeros((num_neurons, 25, 25))\n",
    "numbins1 = 25\n",
    "sig1 = 1\n",
    "\n",
    "for i in range(num_neurons):\n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                              sspk1[:,i], statistic='mean', \n",
    "                             bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "    mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "    acorr[i, :,:] = pearson_correlate2d(mtot_tmp, mtot_tmp)\n",
    "    rmap[i,:,:]  = mtot_tmp\n",
    "\n",
    "hd_info = np.zeros(num_neurons)\n",
    "for i in range(num_neurons):\n",
    "    mtot, __, circ = binned_statistic(headdirection[movetimes0], sspk1[:,i], statistic = 'mean', bins = 30)\n",
    "    mu = np.mean(sspk1[:,i])\n",
    "    hd_info[i] = information_score_1d(mtot, circ-1, mu)\n",
    "\n",
    "scores = (('rmap', rmap), ('acorr2d', acorr), ('sum', np.sum(sspk1,0)), ('hd_info', hd_info))\n",
    "\n",
    "rel_inds = np.where((bin_ind>=30) & (bin_ind<=500))[0]                             \n",
    "for i in rel_inds:\n",
    "    mod_ind1s = np.where(ind1==i)[0]\n",
    "    if len(mod_ind1s)>=2:\n",
    "        print('Mod ', i)\n",
    "        print('num_neurons ', len(mod_ind1s))\n",
    "        print(mod_ind1s)\n",
    "        sspk2 = sspk1[:,mod_ind1s]\n",
    "        sspk2 = preprocessing.scale(sspk2)\n",
    "\n",
    "        scores_cluster(sspk2, scores,  mod_ind1s,headpos[movetimes0,0], headpos[movetimes0, 1], spk2 = [], \n",
    "                       num_example = 6, dim = min(10, len(mod_ind1s)), bUMAP = False)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "sspk2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 1200\n",
    "dim = 5\n",
    "eps = 0.2\n",
    "k = 1000\n",
    "spk1 = preprocessing.scale(sspk2,axis = 0)\n",
    "dim_red_spikes_move_scaled_bu, e1, e2, var_exp = pca(spk1, dim = dim)\n",
    "dim_red_spikes_move_scaled_bu /= np.sqrt(e2[:dim])                        \n",
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled_bu),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled_bu, metric = 'euclidean', \n",
    "                                 epsilon = eps, startindex = startindex)\n",
    "indstemp = []\n",
    "if n_points > len(movetimes1):\n",
    "    n_points = len(movetimes1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eaae66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled_bu[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric = 'cosine')[0]\n",
    "indstemp = movetimes1[indstemp]\n",
    "for n_points in [1200,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    times  = movetimes0[indstemp].copy()\n",
    "    dgms = persistence['dgms']\n",
    "\n",
    "\n",
    "    coords_mod2 = coords_ds_consistent.T*2*np.pi\n",
    "\n",
    "    inds, inds_label =  get_coord_distribution(coords_mod2, numbins = 50,epsilon = 0.1, metric = 'euclidean', startindex = -1)\n",
    "    phases_1 = get_phases(sspk2[indstemp,:], coords_mod2, inds, inds_label)  \n",
    "    pcorr1 = match_phases(coords_mod2, sspk2[indstemp,:], phases_1)\n",
    "\n",
    "    # -ab\n",
    "    coords_mod1 = coords_mod2.copy()\n",
    "    coords_mod1[:,0] = 2*np.pi - coords_mod1[:,0]\n",
    "    phases_2 = get_phases(sspk2[indstemp,:], coords_mod1, inds, inds_label)  \n",
    "    pcorr2 = match_phases(coords_mod1, sspk2[indstemp,:], phases_2)\n",
    "    if np.median(pcorr2)> np.median(pcorr1):\n",
    "        coords_ds_consistent[:,0] = 1 - coords_ds_consistent[:,0]\n",
    "        pcorr1 = pcorr2\n",
    "        phases_1 = phases_2\n",
    "    print(np.median(pcorr1))\n",
    "\n",
    "    pcorrsqr = match_phases(coords_mod2, sspk2[indstemp,:], phases_1, bSqr = True)\n",
    "\n",
    "\n",
    "    fig = plot_barcode(dgms)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "\n",
    "    coords_mod1 = get_coords_all(sspk2, \n",
    "                                 coords_ds_consistent,\n",
    "                                 np.arange(len(sspk2)),                             \n",
    "                                 indstemp,\n",
    "                                 dim = dim, \n",
    "                                 spk2 = sspk2,\n",
    "                                 bPCA = True,\n",
    "                                 bPred = False)\n",
    "\n",
    "    for i in range(3):\n",
    "        coords_mod1 += 1*i\n",
    "        coords_mod1 = coords_mod1%(2*np.pi)\n",
    "        fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "        for c in [0,1,]:\n",
    "\n",
    "            mtot, __, __, circ  = binned_statistic_2d(xx1[times1][movetimes00],\n",
    "                                                      yy1[times1][movetimes00],\n",
    "                                                      coords_mod1[movetimes00,c], \n",
    "                                                      statistic = circmean, \n",
    "                                                      bins = 50,\n",
    "                                                      expand_binnumbers = True)\n",
    "\n",
    "            nans = np.isnan(mtot)\n",
    "            sintot = np.sin(mtot)\n",
    "            costot = np.cos(mtot)\n",
    "            sintot[nans] = np.mean(sintot[~nans])\n",
    "            costot[nans] = np.mean(costot[~nans])\n",
    "            sintot = gaussian_filter(sintot,sig)\n",
    "            costot = gaussian_filter(costot,sig)\n",
    "            mtot = np.cos(np.arctan2(sintot, costot))\n",
    "            plt.viridis()\n",
    "            mtot[nans] = np.nan\n",
    "            axs1[c].imshow(mtot)\n",
    "            axs1[c].axis('off')\n",
    "            axs1[c].set_aspect(1/axs1[c].get_data_ratio())\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e72888",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_points in [1000,]:\n",
    "    print('n_points', n_points)\n",
    "    if (len(indstemp)>0) & (n_points > len(indstemp)):\n",
    "        continue\n",
    "    indstemp = indstemp[:n_points]\n",
    "    dim_red_spikes_move_scaled = dim_red_spikes_move_scaled_bu[indstemp,:]\n",
    "\n",
    "    d = squareform(pdist(dim_red_spikes_move_scaled[:,:], 'cosine'))\n",
    "    thresh = np.max(d[~np.isinf(d)])    \n",
    "    persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)   \n",
    "    print('movetimes1', len(movetimes1))\n",
    "    n_points = len(indstemp)\n",
    "\n",
    "    coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1], bConsistent = True)\n",
    "    times  = movetimes0[indstemp].copy()\n",
    "    dgms = persistence['dgms']\n",
    "\n",
    "\n",
    "    coords_mod2 = coords_ds_consistent.T*2*np.pi\n",
    "\n",
    "    inds, inds_label =  get_coord_distribution(coords_mod2, numbins = 50,epsilon = 0.1, metric = 'euclidean', startindex = -1)\n",
    "    phases_1 = get_phases(sspk2[indstemp,:], coords_mod2, inds, inds_label)  \n",
    "    pcorr1 = match_phases(coords_mod2, sspk2[indstemp,:], phases_1)\n",
    "\n",
    "    # -ab\n",
    "    coords_mod1 = coords_mod2.copy()\n",
    "    coords_mod1[:,0] = 2*np.pi - coords_mod1[:,0]\n",
    "    phases_2 = get_phases(sspk2[indstemp,:], coords_mod1, inds, inds_label)  \n",
    "    pcorr2 = match_phases(coords_mod1, sspk2[indstemp,:], phases_2)\n",
    "    if np.median(pcorr2)> np.median(pcorr1):\n",
    "        coords_ds_consistent[:,0] = 1 - coords_ds_consistent[:,0]\n",
    "        pcorr1 = pcorr2\n",
    "        phases_1 = phases_2\n",
    "    print(np.median(pcorr1))\n",
    "\n",
    "    pcorrsqr = match_phases(coords_mod2, sspk2[indstemp,:], phases_1, bSqr = True)\n",
    "\n",
    "\n",
    "    fig = plot_barcode(dgms)\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(var_exp[:15], lw = 2.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds)):\n",
    "        ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "    ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "    for i in range(len(coords_ds_consistent)):\n",
    "        ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "    ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "    for i in range(3):\n",
    "        ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "    coords_mod1 = get_coords_all(sspk2, \n",
    "                                 coords_ds,\n",
    "                                 np.arange(len(sspk2)),                             \n",
    "                                 indstemp,\n",
    "                                 dim = dim, \n",
    "                                 spk2 = sspk2,\n",
    "                                 bPCA = True,\n",
    "                                 bPred = False)\n",
    "\n",
    "\n",
    "    xx1 = headpos[movetimes0,0]\n",
    "    yy1 = headpos[movetimes0,1]\n",
    "    sig = 1\n",
    "    plt.hsv()\n",
    "    fig1, axs1 = plt.subplots(1,2, figsize = (6,4), dpi = 120)\n",
    "    for c in [0,1,]:\n",
    "\n",
    "        axs1[c].scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hsv()\n",
    "fig1, axs1 = plt.subplots(1,1, figsize = (10,10), dpi = 120)\n",
    "\n",
    "for c in [0,]:\n",
    "\n",
    "    axs1.scatter(xx1,yy1, c = coords_mod1[:,c], s = 5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6b95c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bd715",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hsv()\n",
    "plt.scatter(xx1,yy1, c = coords_mod1[:,0], s = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a802a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(coords_mod1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf1fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa93985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spks = preprocessing.minmax_scale(sspikes,axis = 0)>0.2\n",
    "for it, i in enumerate([11, 28, 183, 191, 126,133,120, 128, 140, 142,\n",
    "                       2,4,  123,53,  21, 146, 178, 9, 17, 137,]):#np.unique(np.random.randint(len(dff[0,:]), size = 20)):\n",
    "\n",
    "    plt.figure(figsize = (5,5), dpi = 120)\n",
    "    plt.axis('off')\n",
    "    plt.scatter(headpos[:,0],headpos[:,1], c = [[0.2,0.2,0.2]], alpha = 0.4, s = 2)\n",
    "    plt.scatter(headpos[spks[:,i],0],headpos[spks[:,i],1], c = 'r', alpha = 0.7, s = 10)\n",
    "    plt.savefig('Figs/' + mouse + '_' + sess + '/spk_map' + str(i) + '.png', transparent = True)\n",
    "    plt.savefig('Figs/' + mouse + '_' + sess + '/spk_map' + str(i) + '.pdf', transparent = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16fdbac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mouse = '97045'\n",
    "for sess in ['20210305', '20210307', '20210308', '20210317']:\n",
    "    shuf_all = {}\n",
    "    shuffle_name1 = 'weijan/' + mouse + '_' + sess + '_shuffles_concatenated.npz'\n",
    "    shuffle_name2 = 'weijan/' + mouse + '_' + sess + '_shuffles_concatenated_2.npz'\n",
    "    shuffle_name3 = 'weijan/' + mouse + '_' + sess + '_shuffles_concatenated3'\n",
    "    shuf = np.load(shuffle_name1, allow_pickle = True)\n",
    "    shuf1 = shuf['dgms_shuffles'][()]\n",
    "    shuf.close()\n",
    "    for s in shuf1:\n",
    "        shuf_all[s] = shuf1[s]\n",
    "        \n",
    "    shuf = np.load(shuffle_name2, allow_pickle = True)\n",
    "    shuf2 = shuf['dgms_shuffles'][()]\n",
    "    shuf.close()\n",
    "    for s in shuf2:\n",
    "        shuf_all[s] = shuf2[s]\n",
    "    np.savez(shuffle_name3, dgms_shuffles = shuf_all)\n",
    "        \n",
    "    \n",
    "    f = np.load('weijan/' + mouse + '_' + sess + '_H2.npz', allow_pickle = True)\n",
    "    dgms = list(f['dgms'])\n",
    "    f.close()\n",
    "    fig = plot_barcode(dgms, shuffle_name = shuffle_name3)\n",
    "    fig.savefig('Figs/' + mouse + '_' + sess + '_barcode.png', transparent = True)\n",
    "    fig.savefig('Figs/' + mouse + '_' + sess + '_barcode.pdf', transparent = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b02c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coords_aligned = {}\n",
    "for sess in sessall:\n",
    "    coords_mod1 = coords_all[sess].copy()\n",
    "    headpos = xy_all[sess].copy()\n",
    "    movetimes0 = movetimes_all[sess].copy()\n",
    "    if sess == '20210305':\n",
    "        print('') \n",
    "    elif sess == '20210307':\n",
    "        coords_mod1[:,0] += 2/np.sqrt(3)*coords_mod1[:,1]\n",
    "    elif sess == '20210308':\n",
    "        ctmp = coords_mod1[:,0].copy()\n",
    "        coords_mod1[:,0] = 2*np.pi-coords_mod1[:,1]\n",
    "        coords_mod1[:,1] = ctmp.copy()+ 2/np.sqrt(3)*coords_mod1[:,0]\n",
    "    elif sess == '20210317':\n",
    "        coords_mod1[:,1] += 2/np.sqrt(3)*coords_mod1[:,0]\n",
    "    coords_mod1 = coords_mod1%(2*np.pi)\n",
    "    coords_aligned[sess] = coords_mod1.copy()\n",
    "    for c in [0,1,]:\n",
    "        fig, axs = plt.subplots(1,1)\n",
    "        nans0 = ~np.isnan(coords_mod1[:,c])\n",
    "        mtot, __, __, circ  = binned_statistic_2d(headpos[movetimes0,0][nans0],\n",
    "                                                  headpos[movetimes0,1][nans0],\n",
    "                                                  coords_mod1[:,c][nans0], \n",
    "                                                  statistic = circmean, \n",
    "                                                  bins = 50,\n",
    "                                                  expand_binnumbers = True)\n",
    "\n",
    "        nans = np.isnan(mtot)\n",
    "        sintot = np.sin(mtot)\n",
    "        costot = np.cos(mtot)\n",
    "        sintot[nans] = np.mean(sintot[~nans])\n",
    "        costot[nans] = np.mean(costot[~nans])\n",
    "        sintot = gaussian_filter(sintot,sig)\n",
    "        costot = gaussian_filter(costot,sig)\n",
    "        mtot = np.cos(np.arctan2(sintot, costot))\n",
    "#            mtot = gaussian_filter(mtot, 1)\n",
    "        plt.viridis()\n",
    "        mtot[nans] = np.nan\n",
    "        axs.imshow(mtot)\n",
    "        axs.axis('off')\n",
    "        axs.set_aspect(1/axs.get_data_ratio())\n",
    "        fig.savefig('Figs/' + mouse + '_' + sess + '_stripes' + str(c) + '.png', transparent = True)\n",
    "        fig.savefig('Figs/' + mouse + '_' + sess + '_stripes' + str(c) + '.pdf', transparent = True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608260bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sess in sessall:\n",
    "    coords_mod1 = coords_all[sess].copy()\n",
    "    headpos = xy_all[sess].copy()\n",
    "    movetimes0 = movetimes_all[sess].copy()\n",
    "    coords_mod1 = coords_aligned[sess].copy()\n",
    "\n",
    "    im = plt.imread('C:\\\\Users\\\\Finnern\\\\OneDrive - NTNU\\\\Giocomo\\\\image044.png')\n",
    "    im = np.array(im)\n",
    "    a1 = np.rot90(im, 1)\n",
    "    sp = -np.inf\n",
    "    sig = 1\n",
    "\n",
    "    cc = np.arctan2(gaussian_filter1d(np.sin(coords_mod1),sigma = sig,axis = 0),\n",
    "                   gaussian_filter1d(np.cos(coords_mod1),sigma = sig,axis = 0))%(2*np.pi)\n",
    "    bCos = True\n",
    "    if bCos:\n",
    "        eps = 0.0001 \n",
    "        digitized = np.concatenate((np.digitize(np.cos(cc[:, 0]), np.linspace(-1-eps,1+eps, len(a1)+1))[:,np.newaxis], \n",
    "                            np.digitize(np.cos(cc[:, 1]), np.linspace(-1-eps,1+eps, len(a1)+1))[:,np.newaxis]),1)\n",
    "    else:\n",
    "        digitized = np.concatenate((np.digitize(cc[:, 0], np.linspace(0,2*np.pi, len(a1)+1))[:,np.newaxis], \n",
    "                                   np.digitize(cc[:, 1], np.linspace(0,2*np.pi, len(a1)+1))[:,np.newaxis]),1)\n",
    "    cc1 = []\n",
    "    for i in range(len(digitized)):\n",
    "        cc1.append(a1[digitized[i,1]-1, digitized[i,0]-1]) \n",
    "    fig = plt.figure(figsize = (10,5), dpi = 200)\n",
    "    plt.axis('off')\n",
    "    plt.hsv()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.axis('off')\n",
    "    im = ax1.scatter(headpos[movetimes0,0], headpos[movetimes0,1], s = 7, c = cc1, alpha  =0.7)\n",
    "    ax1.set_aspect(1/ax1.get_data_ratio())\n",
    "#    plt.show()\n",
    "    fig.savefig('Figs/' + mouse + '_' + sess + '_stripes' + str(c) + '_2dcoords.png', transparent = True)\n",
    "    fig.savefig('Figs/' + mouse + '_' + sess + '_stripes' + str(c) + '_2dcoords.pdf', transparent = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4900e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "f = np.load('weijan\\\\97045_20210308_glm.npz', allow_pickle = True)\n",
    "tor3 = f['tor3'][()][:,0,0]\n",
    "space3 = f['space3'][()][:,0,0]\n",
    "f.close()                \n",
    "\n",
    "from matplotlib.collections import PathCollection\n",
    "import cv2 as cv\n",
    "numbins1 = 30\n",
    "sig1 = 2\n",
    "roll = 3\n",
    "plt.viridis()\n",
    "for sessit, sess in enumerate(sessall):\n",
    "    try:\n",
    "        os.mkdir('Figs/' + mouse + '_' + sess )\n",
    "    except:\n",
    "        print('folder made')\n",
    "        \n",
    "    NAT = h5py.File(data_dir + '/' + mouse + '/' + sess + '/' + 'NAT.mat')\n",
    "    nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "    filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "    tt = nat_all[0,:]\n",
    "    headpos = nat_all[1:3,:].T\n",
    "    headdirection = nat_all[3,:]    \n",
    "    speed = nat_all[4,:]\n",
    "\n",
    "    sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "    for i in range(len(filtered_events)):\n",
    "        if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "            continue\n",
    "        if np.isnan(filtered_events[i,0]):\n",
    "            sspikes[1:-1,i] = interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "        else:\n",
    "            sspikes[1:-1,i] = interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "    \n",
    "        \n",
    "    sspikes = sspikes[1:-1,:]\n",
    "    tt = tt[1:-1]\n",
    "    headpos = headpos[1:-1,:]\n",
    "    speed = speed[1:-1]\n",
    "    \n",
    "    NeuronInformation = sio.loadmat(data_dir + '/' + mouse + '/' + sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "    repremove = np.ones(len(sspikes[0,:]), dtype = bool)\n",
    "    repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "    sspikes = sspikes[:, repremove]\n",
    "    sspikes[np.isnan(sspikes)] = 0\n",
    "    sspikes[sspikes<0.001] = 0\n",
    "    spksum = np.mean(sspikes,0)\n",
    "    plt.plot(np.sort(spksum))\n",
    "    indssort = np.where((spksum>0) & (spksum<10))   [0]\n",
    "    \n",
    "    movetimes0 = np.where(speed>5)[0]\n",
    "    sspk1 = sspikes[:,indssort][movetimes0,:]#,sigma = 1, axis = 0)[:,indssort][movetimes0,:]\n",
    "    spknull0 = sspk1.sum(0)>0\n",
    "    sspk1 = sspk1[:, spknull0 ]\n",
    "    spknull = np.sum(sspk1,1)>0\n",
    "    sspk1 = sspk1[spknull,:]\n",
    "    movetimes0 = movetimes0[spknull]\n",
    "    \n",
    "    xy_all[sess] = headpos.copy()\n",
    "    movetimes_all[sess] = movetimes0.copy()\n",
    "            \n",
    "    num_neurons = len(sspk1[0,:])\n",
    "    pp = coords_aligned[sess].copy()%(2*np.pi)\n",
    "\n",
    "    \n",
    "    numfigs = 2\n",
    "    numw = 8\n",
    "    numh = int(np.ceil(num_neurons/numw))\n",
    "    outer1 = gridspec.GridSpec(1, numw)\n",
    "    fig = plt.figure(figsize=(np.ceil((numw*numfigs+numw-1)*1.05), np.ceil(numh*1.1)))\n",
    "    len_acorr = 500 #len(acorr_sess[fi][0,:])\n",
    "    nw = 0\n",
    "    torsort = np.flip(np.argsort(tor3))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tor3[np.isnan(tor3)] = 0\n",
    "space3[np.isnan(space3)] = 0\n",
    "numfigs = 2\n",
    "numw = 12\n",
    "numh = int(np.ceil(num_neurons/numw))\n",
    "outer1 = gridspec.GridSpec(1, numw)\n",
    "fig = plt.figure(figsize=(np.ceil((numw*numfigs+numw-1)*1.05), np.ceil(numh*1.1)))\n",
    "len_acorr = 500 #len(acorr_sess[fi][0,:])\n",
    "nw = 0\n",
    "torsort = np.flip(np.argsort(tor3))\n",
    "for nn, n in enumerate(range(num_neurons)):\n",
    "    nnn = nn%numh\n",
    "\n",
    "    if nnn == 0:\n",
    "        outer2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec = outer1[nw], wspace = .3)\n",
    "        gs2 = gridspec.GridSpecFromSubplotSpec(numh, numfigs, subplot_spec = outer2[0], hspace = 0.2,wspace = .0)\n",
    "        nw += 1\n",
    "    xnum = 0\n",
    "    spk = sspk1[:,torsort[n]].copy()\n",
    "\n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  spk, statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "    mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "    mtot_tmp[nans] = np.nan\n",
    "\n",
    "    ax = plt.subplot(gs2[nnn,xnum]) \n",
    "#        ax.set_title(str(np.round(tor3[torsort[n]],2)) + ' | '\n",
    "#                     + str(np.round(space3[torsort[n]],2)), fontdict = {'fontsize':10}, pad = 0.25)\n",
    "    xnum += 1\n",
    "    maxtot = np.sort(mtot_tmp.flatten())\n",
    "    maxtot = maxtot[int(0.975*len(maxtot))]\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', extent = [0,2*np.pi,0, 2*np.pi], vmin = 0, vmax = maxtot)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "\n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(pp[:,0], pp[:,1],\n",
    "                                          spk, statistic='mean', \n",
    "                                         bins=numbins1, range=None, expand_binnumbers=True)\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    mtot_tmp = smooth_tuning_map(np.rot90(mtot_tmp,1), numbins1+1, sig1, bClose = True) \n",
    "    mtot_tmp[nans] = -np.inf\n",
    "    ax = plt.subplot(gs2[nnn,xnum]) \n",
    "    xnum += 1\n",
    "    maxtot = np.sort(mtot_tmp.flatten())\n",
    "    maxtot = maxtot[int(0.975*len(maxtot))]\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', extent = [0,2*np.pi,0, 2*np.pi], vmin = 0, vmax = maxtot)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1/ax.get_data_ratio())\n",
    "    r_box = transforms.Affine2D().skew_deg(15,15)\n",
    "\n",
    "    for x in ax.images + ax.lines + ax.collections:\n",
    "        trans = x.get_transform()\n",
    "        x.set_transform(r_box+trans) \n",
    "        if isinstance(x, PathCollection):\n",
    "            transoff = x.get_offset_transform()\n",
    "            x._transOffset = r_box+transoff     \n",
    "    ax.set_xlim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_ylim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_aspect('equal', 'box') \n",
    "    ax.axis('off')   \n",
    "fig.savefig('Figs/' + mouse +'_' + sess+ '/torall.png', transparent = True)\n",
    "fig.savefig('Figs/' + mouse +'_' + sess+ '/torall.pdf', transparent = True)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sess in sessall[2:3]:\n",
    "    f = np.load(data_dir + '/' + mouse + '/' + sess + '/decoding_data.npz')\n",
    "    indstemp = f['indstemp']\n",
    "    coords_ds = f['coords_ds']\n",
    "    f.close()\n",
    "    sspk1 = np.sqrt(spk_all[sess])    \n",
    "    coords_mod1 = coords_ds.T*2*np.pi\n",
    "    headpos = xy_all[sess].copy()\n",
    "    movetimes0 = movetimes_all[sess].copy()\n",
    "    if sess == '20210305':\n",
    "        print('') \n",
    "    elif sess == '20210307':\n",
    "        coords_mod1[:,0] += 2/np.sqrt(3)*coords_mod1[:,1]\n",
    "    elif sess == '20210308':\n",
    "        ctmp = coords_mod1[:,0].copy()\n",
    "        coords_mod1[:,0] = 2*np.pi-coords_mod1[:,1]\n",
    "        coords_mod1[:,1] = ctmp.copy()+ 2/np.sqrt(3)*coords_mod1[:,0]\n",
    "    elif sess == '20210317':\n",
    "        coords_mod1[:,1] += 2/np.sqrt(3)*coords_mod1[:,0]\n",
    "    coords_mod1 = coords_mod1%(2*np.pi)\n",
    "    coords_ds = coords_mod1.T/(2*np.pi)\n",
    "    coords_ds[0,:] = 1-coords_ds[0,:]\n",
    "    starttime = 1000\n",
    "    num_frames = 1000\n",
    "    coordsnew_mod22 = get_coords_distribution1(sspk1, \n",
    "                                           sspk1, \n",
    "                                           coords_ds, indstemp, \n",
    "                                           starttime = starttime, num_frames = num_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f61ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation, cm, transforms, pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from matplotlib.collections import PathCollection\n",
    "headpos1 = np.flip(preprocessing.minmax_scale(headpos,axis = 0)[movetimes0],1)\n",
    "headpos1[:,0] = 1-headpos1[:,0]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax.axis('off') \n",
    "ax.set_aspect('equal','box')\n",
    "img = ax.scatter([], [], zorder = -1)\n",
    "ax.set_ylim( 0, 1)\n",
    "ax.set_xlim( 0, 1)\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_ylim( 0, 2*np.pi+3/5*np.pi)\n",
    "ax2.set_xlim( 0, 2*np.pi+3/5*np.pi)\n",
    "ax2.set_aspect('equal','box')\n",
    "ax2.axis('off')\n",
    "\n",
    "img2 = ax2.imshow(coordsnew_mod22[0,:,:], origin = 'lower',\n",
    "                  extent = [0,2*np.pi, 0, 2*np.pi], vmin = 0, vmax = 20)\n",
    "ax2.text(0.7,-0.65-0.35, '0$\\degree$')\n",
    "ax2.text(2*np.pi-0.6,-0.65-0.35, '360$\\degree$')\n",
    "ax2.text(-0.6-0.45,0.6, '0$\\degree$')\n",
    "ax2.text(-0.85-0.65,2*np.pi-0.35,'360$\\degree$')\n",
    "\n",
    "im = [img, img2,]\n",
    "def init():\n",
    "    im[0].set_offsets(np.array([[],[]]).T)\n",
    "    im[1].set_data([[]])\n",
    "    return im\n",
    "\n",
    "r_box = transforms.Affine2D().skew_deg(15,15)\n",
    "for x in (ax2.images + ax2.lines + ax2.collections + ax2.texts):\n",
    "    trans = x.get_transform()\n",
    "    x.set_transform(r_box+trans) \n",
    "    if isinstance(x, PathCollection):\n",
    "        transoff = x.get_offset_transform()\n",
    "        x._transOffset = r_box+transoff     \n",
    "\n",
    "\n",
    "fps = 25\n",
    "height, width = 1600, 1600\n",
    "\n",
    "def animate(i):\n",
    "    i+= starttime    \n",
    "    im[0].set_offsets(headpos1[starttime:i+1,:])\n",
    "    im[1].set_data(np.rot90(coordsnew_mod22[i-starttime,:,:],3))    \n",
    "    return im\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=1000, interval=100, blit=True)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222196d2",
   "metadata": {},
   "source": [
    "## Plot ratemaps according to GLM score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ff1d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = np.load('weijan/' + mouse + '_' + sess + '_glm.npz', allow_pickle = True)\n",
    "\n",
    "argwhere = np.argsort(tor3)\n",
    "#argwhere = argwhere[(np.linspace(0, 1, 17)[np.arange(1,16,2)]*len(tor3)).astype(int)]\n",
    "argwhere = argwhere[np.round(np.linspace(0, 1, 11)[np.arange(1,11,2)]*len(tor3)).astype(int)]\n",
    "from matplotlib.collections import PathCollection\n",
    "import cv2 as cv\n",
    "numbins1 = 30\n",
    "sig1 = 2\n",
    "roll = 3\n",
    "\n",
    "plt.viridis()\n",
    "\n",
    "try:\n",
    "    os.mkdir('Figs/' + mouse + '_' + sess )\n",
    "except:\n",
    "    print('folder made')\n",
    "\n",
    "NAT = h5py.File(data_dir + '/' + mouse + '/' + sess + '/' + 'NAT.mat')\n",
    "nat_all = NAT[NAT['NAT'][()][0][0]][()]\n",
    "filtered_events = nat_all[np.arange(15,len(nat_all), 4),:]\n",
    "tt = nat_all[0,:]\n",
    "headpos = nat_all[1:3,:].T\n",
    "headdirection = nat_all[3,:]    \n",
    "speed = nat_all[4,:]\n",
    "\n",
    "sspikes = np.zeros(np.shape(filtered_events)).T\n",
    "for i in range(len(filtered_events)):\n",
    "    if np.sum(np.isnan(filtered_events[i,:]))== len(tt):\n",
    "        continue\n",
    "    if np.isnan(filtered_events[i,0]):\n",
    "        sspikes[1:-1,i] = interp1d(tt[np.arange(1,len(tt),2)], filtered_events[i,np.arange(1,len(tt),2)])(tt[1:-1])\n",
    "    else:\n",
    "        sspikes[1:-1,i] = interp1d(tt[np.arange(0,len(tt),2)], filtered_events[i,np.arange(0,len(tt),2)])(tt[1:-1])    \n",
    "\n",
    "\n",
    "sspikes = sspikes[1:-1,:]\n",
    "tt = tt[1:-1]\n",
    "headpos = headpos[1:-1,:]\n",
    "speed = speed[1:-1]\n",
    "\n",
    "NeuronInformation = sio.loadmat(data_dir + '/' + mouse + '/' + sess + '/' + 'NeuronInformation.mat')['NeuronInformation']\n",
    "repremove = np.ones(len(sspikes[0,:]), dtype = bool)\n",
    "repremove[NeuronInformation['RepeatCell'][()][0,0][0].astype(int)-1] = False\n",
    "sspikes = sspikes[:, repremove]\n",
    "sspikes[np.isnan(sspikes)] = 0\n",
    "sspikes[sspikes<0.001] = 0\n",
    "spksum = np.mean(sspikes,0)\n",
    "plt.plot(np.sort(spksum))\n",
    "indssort = np.where((spksum>0) & (spksum<10))   [0]\n",
    "\n",
    "movetimes0 = np.where(speed>5)[0]\n",
    "sspk1 = sspikes[:,indssort][movetimes0,:]#,sigma = 1, axis = 0)[:,indssort][movetimes0,:]\n",
    "spknull0 = sspk1.sum(0)>0\n",
    "sspk1 = sspk1[:, spknull0 ]\n",
    "spknull = np.sum(sspk1,1)>0\n",
    "sspk1 = sspk1[spknull,:]\n",
    "movetimes0 = movetimes0[spknull]\n",
    "\n",
    "xy_all[sess] = headpos.copy()\n",
    "movetimes_all[sess] = movetimes0.copy()\n",
    "\n",
    "num_neurons = len(sspk1[0,:])\n",
    "pp = coords_all[sess].copy()%(2*np.pi)\n",
    "\n",
    "\n",
    "for it,  n in enumerate(argwhere):#enumerate(IsGridCell[:5].astype(int)):    \n",
    "    print(tor3[n], space3[n])\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(headpos[movetimes0,0], headpos[movetimes0,1],\n",
    "                                  sspk1[:,n], statistic='mean', \n",
    "                                 bins=numbins1, range=None, expand_binnumbers=True)\n",
    "\n",
    "\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[nans] = np.mean(mtot_tmp[~nans])\n",
    "    mtot_tmp = gaussian_filter(mtot_tmp,sigma = sig1)\n",
    "    mtot_tmp[nans] = np.nan\n",
    "\n",
    "    ax = axs[0]\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', extent = [0,2*np.pi,0, 2*np.pi], vmin = 0, vmax = np.max(mtot_tmp) *0.975)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    mtot_tmp, x_edge, y_edge,c2 = binned_statistic_2d(pp[:,0], pp[:,1],\n",
    "                                          sspk1[:,n], statistic='mean', \n",
    "                                         bins=numbins1, range=None, expand_binnumbers=True)\n",
    "    nans = np.isnan(mtot_tmp)\n",
    "    mtot_tmp[np.isnan(mtot_tmp)] = np.mean(mtot_tmp[~np.isnan(mtot_tmp)])\n",
    "    mtot_tmp = smooth_tuning_map(np.rot90(mtot_tmp,1), numbins1+1, sig1, bClose = True) \n",
    "    mtot_tmp[nans] = -np.inf\n",
    "    ax = axs[1]\n",
    "    ax.imshow(mtot_tmp, origin = 'lower', extent = [0,2*np.pi,0, 2*np.pi], vmin = 0, vmax = np.max(mtot_tmp) *0.975)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1/ax.get_data_ratio())\n",
    "    r_box = transforms.Affine2D().skew_deg(15,15)\n",
    "\n",
    "    for x in ax.images + ax.lines + ax.collections:\n",
    "        trans = x.get_transform()\n",
    "        x.set_transform(r_box+trans) \n",
    "        if isinstance(x, PathCollection):\n",
    "            transoff = x.get_offset_transform()\n",
    "            x._transOffset = r_box+transoff     \n",
    "    ax.set_xlim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_ylim(0, 2*np.pi + 3*np.pi/5)\n",
    "    ax.set_aspect('equal', 'box') \n",
    "    ax.axis('off')   \n",
    "#    plt.show()\n",
    "#    fig.savefig('Figs/' + mouse +'_' + sess+ '/ratemap' + str(it) + '.png', transparent = True, pad_inches = 0.1)\n",
    "#    fig.savefig('Figs/' + mouse +'_' + sess+ '/ratemap' + str(it) + '.pdf', transparent = True, pad_inches = 0.1)\n",
    "#    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d218b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize = (5,5), dpi = 120)\n",
    "ax.plot([-0.1,0.6],[-0.1,0.6], c = 'k', ls = ':', alpha  =0.6)\n",
    "ax.scatter(space3, tor3, s = 30, alpha = 0.75)\n",
    "ax.scatter(space3[argwhere], tor3[argwhere], c = 'r', marker = 'X', s = 150, lw = 0.1)\n",
    "ax.set_xlim([-0.1,0.6])\n",
    "ax.set_ylim([-0.1,0.6])\n",
    "ax.set_yticklabels('')\n",
    "ax.set_xticklabels('')\n",
    "ax.set_yticklabels('')\n",
    "ax.set_aspect(1/ax.get_data_ratio())\n",
    "fig.savefig('Figs/' + mouse +'_' + sess+ '/explained_variance.png', transparent = True, pad_inches = 0.1)\n",
    "fig.savefig('Figs/' + mouse +'_' + sess+ '/explained_variance.pdf', transparent = True, pad_inches = 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cdd86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3e1ad0d",
   "metadata": {},
   "source": [
    "## CEBRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cebra import CEBRA\n",
    "cebra_time3_model = CEBRA(model_architecture='offset10-model',\n",
    "                    batch_size=128,\n",
    "                    learning_rate=0.001,\n",
    "                    temperature=1.12,\n",
    "                    output_dimension=3,\n",
    "                    max_iterations=1000,\n",
    "                    distance='cosine',\n",
    "                    conditional='time',\n",
    "                    device='cuda_if_available',\n",
    "                    verbose=True,\n",
    "                    time_offsets=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_time3_model.fit(dim_red_spikes_move_scaled_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_dec = cebra_time3_model.transform(sspk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_dec = cebra_time3_model.transform(dim_red_spikes_move_scaled_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9552f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10), dpi = 120)\n",
    "ax = fig.add_subplot(111,)\n",
    "ax.scatter(cebra_dec[:,0], cebra_dec[:,1], s = 100, c = hd)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f8f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(CEBRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde29992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.hsv()\n",
    "for ii in [-60,0, 60]:\n",
    "    for jj in [-90, 0, 90, ]:\n",
    "        print(ii,jj)\n",
    "        fig = plt.figure(figsize = (10,10), dpi = 120)\n",
    "        ax = fig.add_subplot(111, projection = '3d')\n",
    "        ax.scatter(cebra_dec[:,0], cebra_dec[:,1], cebra_dec[:,2], s = 5, c = hd)\n",
    "        ax.view_init(ii,jj)\n",
    "        ax.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
