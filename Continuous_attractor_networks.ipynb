{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "dir1 = '/Users/erihe/OneDrive - NTNU/'\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "from utils_new import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = '/Users/erihe/OneDrive - NTNU/Prosjekt/Main'\n",
    "# if >0, plots the sheet of activity during the simulation on every livePlot'th step\n",
    "livePlot = 100\n",
    "\n",
    "# if =0, just give constant velocity. if =1, load trajectory from disk\n",
    "useRealTrajectory = 1\n",
    "constantVelocity = 1*[.0005, 0*0.0005] # m/s\n",
    "\n",
    "## Network/Weight matrix parameters\n",
    "Nx = 10 # number of cells in x direction\n",
    "Ny = 10 # number of cells in y direction\n",
    "ncells = Nx*Ny # total number of cells in network\n",
    "# grid spacing is approx 1.02 - 0.48*log2(alpha), pg 236\n",
    "alpha = 30 # input gain, unitless\n",
    "beta = 0 # input direction bias (i.e. grid orientation), rad\n",
    "sigma = 0.24 # exponential weight std. deviation\n",
    "I = 0.3 # peak synaptic strength\n",
    "T = 0.05 # shift so tail of exponential weights turn inhibitory\n",
    "tau = 0.8 # relative weight of normalized vs. full-strength synaptic inputs\n",
    "\n",
    "## Simulation parameters\n",
    "dt = 20 # time step, ms\n",
    "simdur = 5*59000 # total simulation time, ms\n",
    "stabilizationTime = 80 # no-velocity time for pattern to form, ms\n",
    "tind = -1 # time step number for indexing\n",
    "t = 0 # simulation time variable, ms\n",
    "A = np.random.rand(ncells)/np.sqrt(ncells) # activation of each cell\n",
    "R = np.linalg.inv(np.array([[np.cos(0), np.cos(np.pi/3)],[ np.sin(0), np.sin(np.pi/3)]]))\n",
    "x = (np.arange(Nx) - 0.5)/Nx\n",
    "y = (np.arange(Ny) - 0.5)/Ny\n",
    "X,Y = np.meshgrid(x,y)\n",
    "x = np.concatenate((X.ravel()[:,np.newaxis],  \n",
    "                    Y.ravel()[:,np.newaxis]),1).T\n",
    "\n",
    "[jx,ix] = np.meshgrid(x[0,:],x[0,:])\n",
    "[jy,iy] = np.meshgrid(x[1,:],x[1,:])\n",
    "jx = jx.ravel()#[np.newaxis,:]#reshape(jx,1,[])\n",
    "ix = ix.ravel()#[np.newaxis,:]#reshape(ix,1,[])\n",
    "jy = jy.ravel()#[np.newaxis,:]#reshape(jy,1,[])\n",
    "iy = iy.ravel()#[np.newaxis,:]#reshape(iy,1,[])\n",
    "W = np.ones(ncells)\n",
    "\n",
    "if useRealTrajectory:\n",
    "    pos = sio.loadmat(data_dir + '/HaftingTraj_centimeters_seconds.mat')\n",
    "    pos = pos['pos']\n",
    "    pos[2,:] *= 1e3;\n",
    "    end = 100000\n",
    "    pos = np.concatenate((np.interp(np.arange(0, pos[2,-1], dt), pos[2,:],pos[0,:])[np.newaxis,:],\n",
    "           np.interp(np.arange(0, pos[2,-1], dt), pos[2,:],pos[1,:])[np.newaxis,:],\n",
    "           np.interp(np.arange(0, pos[2,-1], dt), pos[2,:],pos[2,:])[np.newaxis,:]),0)\n",
    "    pos[:2,:] /= 100\n",
    "    vels = np.concatenate((np.diff(pos[0,:])[:,np.newaxis], np.diff(pos[1,:])[:,np.newaxis]),1)/dt\n",
    "\n",
    "    \n",
    "## Possibly load trajectory from disk\n",
    "## Simulation\n",
    "#simdur = 50000\n",
    "spikes = np.zeros((len(pos[0,:]), ncells))\n",
    "\n",
    "for tind in range(len(pos[0,:])-1):\n",
    "    v = vels[tind,:] # m/s\n",
    "    squaredPairwiseDists = np.zeros((9,len(ix)))                   \n",
    "    squaredPairwiseDists[0,:] = np.square((ix-jx+0+alpha*v[0])) + np.square((iy-jy+0+alpha*v[1]))\n",
    "    squaredPairwiseDists[1,:] = np.square((ix-jx-1+alpha*v[0])) + np.square((iy-jy-1+alpha*v[1]))\n",
    "    squaredPairwiseDists[2,:] = np.square((ix-jx-1+alpha*v[0])) + np.square((iy-jy+0+alpha*v[1]))\n",
    "    squaredPairwiseDists[3,:] = np.square((ix-jx-1+alpha*v[0])) + np.square((iy-jy+1+alpha*v[1]))\n",
    "    squaredPairwiseDists[4,:] = np.square((ix-jx+0+alpha*v[0])) + np.square((iy-jy-1+alpha*v[1]))\n",
    "    squaredPairwiseDists[5,:] = np.square((ix-jx+0+alpha*v[0])) + np.square((iy-jy+1+alpha*v[1]))\n",
    "    squaredPairwiseDists[6,:] = np.square((ix-jx+1+alpha*v[0])) + np.square((iy-jy-1+alpha*v[1]))\n",
    "    squaredPairwiseDists[7,:] = np.square((ix-jx+1+alpha*v[0])) + np.square((iy-jy+0+alpha*v[1]))\n",
    "    squaredPairwiseDists[8,:] = np.square((ix-jx+1+alpha*v[0])) + np.square((iy-jy+1+alpha*v[1]))\n",
    "    squaredPairwiseDists = np.min(squaredPairwiseDists,0)\n",
    "    squaredPairwiseDists = squaredPairwiseDists.reshape(ncells,ncells).T\n",
    "\n",
    "    W = I*np.exp(-squaredPairwiseDists/sigma**2) - T\n",
    "\n",
    "    B = np.matmul(A, W.T)\n",
    "\n",
    "    A = (1-tau)*B + tau*(B/np.sum(A))\n",
    "\n",
    "    A[A<0] = 0\n",
    "    # Save firing field information\n",
    "    spikes[tind,:] = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "    plt.figure()\n",
    "    ax = plt.axes()\n",
    "    ax.scatter(pos[0, :tind],pos[1,:tind],c = spikes[:tind,j], s = 10)\n",
    "    ax.set_aspect(1/ax.get_data_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 8         # number of principal components\n",
    "k = 1000          # number of neighbours for downsampling\n",
    "maxdim = 1        # dimension of homology - often just do 1 as it could be expensive (depends on number of points and neighbours)\n",
    "metric = 'cosine' # what metric to use for persistence\n",
    "eps = 0.2        # radial distance downsampling\n",
    "n_points = 1000   # number of downsampled points for persistence analysis \n",
    "\n",
    "\n",
    "spk1 = preprocessing.scale(spikes,axis = 0)\n",
    "dim_red_spikes_move_scaled, e1, e2, var_exp = pca(spk1, dim = dim)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(var_exp[:15])\n",
    "ax.set_aspect(1/ax.get_data_ratio())\n",
    "fig, axs = plt.subplots(1,dim, figsize= (10,5), dpi = 120)\n",
    "\n",
    "for c in range(dim):\n",
    "    mtot, __, __, circ  = binned_statistic_2d(pos[0, :],\n",
    "                                              pos[1, :],\n",
    "                                              dim_red_spikes_move_scaled[:,c], \n",
    "                                              statistic = 'mean', \n",
    "                                              bins = 30,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    mtot[nans] = np.mean(mtot[~nans])\n",
    "    mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    vals = np.unique(mtot)\n",
    "    mtot[nans] = np.nan\n",
    "    axs[c].imshow(mtot,vmin = vals[int(0.05*len(vals))], vmax = vals[int(0.95*len(vals))])\n",
    "    axs[c].axis('off')\n",
    "    axs[c].set_aspect(1/axs[c].get_data_ratio())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled,  epsilon = eps, \n",
    "    startindex = startindex)\n",
    "\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric)[0]\n",
    "indstemp = movetimes1[indstemp]\n",
    "dim_red_spikes_move_scaled = dim_red_spikes_move_scaled[indstemp,:]\n",
    "\n",
    "indstemp = indstemp[:n_points]\n",
    "dim_red_spikes_move_scaled = dim_red_spikes_move_scaled[:n_points,:]\n",
    "\n",
    "d = squareform(pdist(dim_red_spikes_move_scaled[:,:], metric))\n",
    "thresh = np.max(d[~np.isinf(d)])\n",
    "persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)    \n",
    "dgms = persistence['dgms'] \n",
    "plt.figure()\n",
    "plot_diagrams(dgms, list(np.arange(maxdim+1)), lifetime = True)\n",
    "plt.show()\n",
    "plot_barcode(dgms)\n",
    "\n",
    "coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1,], bConsistent = True)\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "for i in range(len(coords_ds)):\n",
    "    ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "for i in range(3):\n",
    "    ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "for i in range(len(coords_ds)):\n",
    "    ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "for i in range(3):\n",
    "    ax[i].set_aspect(1/ax[i].get_data_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.viridis()\n",
    "\n",
    "numbins = 12\n",
    "coords1 = get_coords_all(spikes, coords_ds_consistent[:,:],   \n",
    "         np.arange(len(spikes)),                             \n",
    "         indstemp, bPCA = False)\n",
    "mcstemp, mtot_all = get_ratemaps_center(coords1, spikes, numbins = numbins,)\n",
    "num_neurons = len(spikes[0,:])\n",
    "spk_sim_hex = get_sim(coords1, mcstemp, numbins = numbins, simtype = 'hex', t = 0.2)\n",
    "spk_sim_sqr = get_sim(coords1, mcstemp, numbins = numbins, simtype = 'sqr', t = 0.2)\n",
    "        \n",
    "for i in np.array(np.random.rand(4)*len(spikes[0,:]), dtype = int):\n",
    "    print(i)\n",
    "    mtot = binned_statistic_2d(pos[0,:][:],pos[1,:][:], spikes[:,i], bins = 25, statistic = 'mean')[0]\n",
    "    mtot1 = binned_statistic_2d(pos[0,:][:],pos[1,:][:], spk_sim_sqr[:,i], bins = 25, statistic = 'mean')[0]\n",
    "    mtot3 = binned_statistic_2d(pos[0,:][:],pos[1,:][:], spk_sim_hex[:,i], bins = 25, statistic = 'mean')[0]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot,\n",
    "              vmin = 0, \n",
    "              vmax = mtot[~np.isnan(mtot)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_simulated_square.png', transparent = True, pad_inches = 0.1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot1,\n",
    "              vmin = 0, \n",
    "              vmax = mtot1[~np.isnan(mtot1)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_sqr_square.png', transparent = True, pad_inches = 0.1)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot3,\n",
    "              vmin = 0, \n",
    "              vmax = mtot3[~np.isnan(mtot3)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_hex_square.png', transparent = True, pad_inches = 0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "mcstemp, mtot_all = get_ratemaps_center(coords1, spikes, numbins = numbins,)\n",
    "fig,ax = plt.subplots(1,1)\n",
    "plot_centered_ratemaps(coords1, spikes, mcstemp, numbins, ax)\n",
    "fig.savefig('stacked_ratemap_square.png', transparent = True, pad_inches = 0.1)\n",
    "fig.savefig('stacked_ratemap_square.pdf', transparent = True, pad_inches = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "im = plt.imread('image044.png')\n",
    "im = np.array(im)\n",
    "a1 = np.rot90(im, 1)\n",
    "sp = -np.inf\n",
    "sig = 1\n",
    "\n",
    "cc = np.arctan2(gaussian_filter1d(np.sin(coords1),sigma = sig,axis = 0),\n",
    "               gaussian_filter1d(np.cos(coords1),sigma = sig,axis = 0))%(2*np.pi)\n",
    "bCos = True\n",
    "if bCos:\n",
    "    eps = 0.0001 \n",
    "    digitized = np.concatenate((np.digitize(np.cos(cc[:, 0]), np.linspace(-1-eps,1+eps, len(a1)+1))[:,np.newaxis], \n",
    "                        np.digitize(np.cos(cc[:, 1]), np.linspace(-1-eps,1+eps, len(a1)+1))[:,np.newaxis]),1)\n",
    "else:\n",
    "    digitized = np.concatenate((np.digitize(cc[:, 0], np.linspace(0,2*np.pi, len(a1)+1))[:,np.newaxis], \n",
    "                               np.digitize(cc[:, 1], np.linspace(0,2*np.pi, len(a1)+1))[:,np.newaxis]),1)\n",
    "cc1 = []\n",
    "for i in range(len(digitized)):\n",
    "    cc1.append(a1[digitized[i,1]-1, digitized[i,0]-1]) \n",
    "fig = plt.figure(figsize = (10,5), dpi = 200)\n",
    "plt.axis('off')\n",
    "plt.hsv()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.axis('off')\n",
    "im = ax1.scatter(pos[0,:], pos[1,:], s = 50, c = cc1, alpha  =0.7)\n",
    "ax1.set_aspect(1/ax1.get_data_ratio())\n",
    "\n",
    "plt.savefig('square_OF_2dcoords', transparent = True, pad_inches = 0.1)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.viridis()\n",
    "plt.imshow(spikes[150,:].reshape(10,10))\n",
    "plt.axis('off')\n",
    "plt.savefig('Pop_vect_square.png', transparent = True,pad_inches = 0.1)\n",
    "plt.savefig('Pop_vect_square.pdf', transparent = True,pad_inches = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guanella hexagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Guanella \n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import scipy.ndimage.filters as filt\n",
    "arena_size = 50\n",
    "\n",
    "arenaX = [0,arena_size]\n",
    "arenaY = [0,arena_size]\n",
    "\n",
    "## Initial position\n",
    "Txx = [arenaX[1]/2]\n",
    "Tyy = [arenaY[1]/2]\n",
    "\n",
    "def conv(ang):\n",
    "    x = np.cos(np.radians(ang)) \n",
    "    y = np.sin(np.radians(ang)) \n",
    "    return x , y\n",
    "\n",
    "def random_navigation(length):\n",
    "    thetaList = []\n",
    "\n",
    "    theta = 90\n",
    "    counter = 0\n",
    "    lenght_counter = 0\n",
    "    for i in range(length):\n",
    "        lenght_counter += 1\n",
    "\n",
    "        prevTheta = np.copy(theta)\n",
    "\n",
    "        if( Txx[-1]<2 ): theta = np.random.randint(-85,85)\n",
    "\n",
    "        if( Txx[-1]>arena_size-2 ): theta = np.random.randint(95,260)\n",
    "\n",
    "        if( Tyy[-1]<2 ): theta = np.random.randint(10,170)\n",
    "\n",
    "        if( Tyy[-1]>arena_size-2 ): theta = np.random.randint(190,350)\n",
    "\n",
    "\n",
    "        Txx.append( Txx[-1]+conv(theta)[0] + np.random.uniform(-0.5,0.5) )\n",
    "        Tyy.append( Tyy[-1]+conv(theta)[1] + np.random.uniform(-0.5,0.5)  )\n",
    "\n",
    "        cx = abs( Txx[-1] - Txx[-2]  )\n",
    "        cy = abs( Tyy[-1] - Tyy[-2]  )\n",
    "        h = np.sqrt( cx**2 + cy**2  )\n",
    "        counter+=h\n",
    "\n",
    "        if(theta != prevTheta or i == length-1):\n",
    "            thetaList.append( [prevTheta, conv(prevTheta)[0], conv(prevTheta)[1], counter]  )\n",
    "            counter = 0\n",
    "    \n",
    "    plt.plot(Txx,Tyy, '-')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "random_navigation(5000)\n",
    "\n",
    "Txx = np.array(Txx)\n",
    "Tyy = np.array(Tyy)\n",
    "\n",
    "class Grid():\n",
    "    def __init__(self, gain):\n",
    "        \n",
    "        self.mm = 20\n",
    "        self.nn = 20\n",
    "        self.TAO = 0.9\n",
    "        self.II = 0.3\n",
    "        self.SIGMA = 0.24\n",
    "        self.SIGMA2 = self.SIGMA**2\n",
    "        self.TT = 0.05\n",
    "        self.grid_gain = gain\n",
    "        self.grid_layers = len(self.grid_gain)  \n",
    "        self.grid_activity = np.random.uniform(0,1,(self.mm,self.nn,self.grid_layers))  \n",
    "        self.distTri = self.buildTopology(self.mm,self.nn)\n",
    "\n",
    "\n",
    "    def update(self, speedVector):\n",
    "\n",
    "        self.speedVector = speedVector\n",
    "        \n",
    "        grid_ActTemp = []\n",
    "        for jj in range(0,self.grid_layers):\n",
    "            rrr = self.grid_gain[jj]*np.exp(1j*0)\n",
    "            matWeights = self.updateWeight(self.distTri,rrr)\n",
    "            activityVect = np.ravel(self.grid_activity[:,:,jj])\n",
    "            activityVect = self.Bfunc(activityVect, matWeights)\n",
    "            activityTemp = activityVect.reshape(self.mm,self.nn)\n",
    "            activityTemp += self.TAO *( activityTemp/np.mean(activityTemp) - activityTemp)\n",
    "            activityTemp[activityTemp<0] = 0\n",
    "\n",
    "            self.grid_activity[:,:,jj] = (activityTemp-np.min(activityTemp))/(  np.max(activityTemp)-np.min(activityTemp)) * 30  ##Eq 2\n",
    "                        \n",
    "\n",
    "    def buildTopology(self,mm,nn):  # Build connectivity matrix     ### Eq 4\n",
    "        mmm = (np.arange(mm)+(0.5/mm))/mm\n",
    "        nnn = ((np.arange(nn)+(0.5/nn))/nn)*np.sqrt(3)/2\n",
    "        xx,yy = np.meshgrid(mmm, nnn)\n",
    "        posv = xx+1j * yy\n",
    "        Sdist = [ 0+1j*0, -0.5+1j*np.sqrt(3)/2, -0.5+1j*(-np.sqrt(3)/2), 0.5+1j*np.sqrt(3)/2, 0.5+1j*(-np.sqrt(3)/2), -1+1j*0, 1+1j*0]      \n",
    "        xx,yy = np.meshgrid( np.ravel(posv) , np.ravel(posv) )\n",
    "        distmat = xx-yy\n",
    "        for ii in range(len(Sdist)):\n",
    "            aaa1 = abs(distmat)\n",
    "            rrr = xx-yy + Sdist[ii]\n",
    "            aaa2 = abs(rrr)\n",
    "            iii = np.where(aaa2<aaa1)\n",
    "            distmat[iii] = rrr[iii]\n",
    "        return distmat.transpose()\n",
    "\n",
    "    def updateWeight(self,topology,rrr): # Slight update on weights based on speed vector.\n",
    "        matWeights = self.II * np.exp((-abs(topology-rrr*self.speedVector)**2)/self.SIGMA2) - self.TT   ## Eq 3\n",
    "        return matWeights\n",
    "\n",
    "    def Bfunc(self,activity, matWeights):  ## Eq 1\n",
    "        activity += np.dot(activity,matWeights)\n",
    "        return activity\n",
    "# this produces grid cells with different scales. Change the list to just one scale for one module\n",
    "scale = [0.06,]\n",
    "grid = Grid(scale)\n",
    "\n",
    "log_grid_cells = []\n",
    "for i in range(1,Txx.size):\n",
    "\n",
    "    speedVector = (Txx[i]-Txx[i-1])+1j*(Tyy[i]-Tyy[i-1])\n",
    "\n",
    "    grid.update(speedVector)\n",
    "    log_grid_cells.append( grid.grid_activity.flatten()  )\n",
    "    \n",
    "log_grid_cells = np.array(log_grid_cells)\n",
    "xx = np.copy(Txx[1:])\n",
    "yy = np.copy(Tyy[1:])\n",
    "dv_levels = [0,5,10]\n",
    "\n",
    "dv_levels = 10\n",
    "dv_start = 25\n",
    "for cell_num in np.arange(dv_levels):\n",
    "\n",
    "    celula = log_grid_cells[:,dv_start+cell_num]\n",
    "\n",
    "    pos_spike_idx = np.where( celula > celula.max()*.9 )[0]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(xx,yy)\n",
    "    plt.scatter(   xx[pos_spike_idx] , yy[pos_spike_idx], c = 'r' )\n",
    "    #ax.set_aspect('equal', 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 6         # number of principal components\n",
    "k = 1000          # number of neighbours for downsampling\n",
    "maxdim = 1        # dimension of homology - often just do 1 as it could be expensive (depends on number of points and neighbours)\n",
    "metric = 'cosine' # what metric to use for persistence\n",
    "eps = 0.2        # radial distance downsampling\n",
    "n_points = 1000   # number of downsampled points for persistence analysis \n",
    "\n",
    "\n",
    "spk1 = preprocessing.scale(log_grid_cells,axis = 0)\n",
    "dim_red_spikes_move_scaled, e1, e2, var_exp = pca(spk1, dim = dim)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(var_exp[:15])\n",
    "ax.set_aspect(1/ax.get_data_ratio())\n",
    "fig, axs = plt.subplots(1,dim, figsize= (10,5), dpi = 120)\n",
    "\n",
    "for c in range(dim):\n",
    "    mtot, __, __, circ  = binned_statistic_2d(xx,\n",
    "                                              yy,\n",
    "                                              dim_red_spikes_move_scaled[:,c], \n",
    "                                              statistic = 'mean', \n",
    "                                              bins = 30,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    mtot[nans] = np.mean(mtot[~nans])\n",
    "    mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    vals = np.unique(mtot)\n",
    "    mtot[nans] = np.nan\n",
    "    axs[c].imshow(mtot,vmin = vals[int(0.05*len(vals))], vmax = vals[int(0.95*len(vals))])\n",
    "    axs[c].axis('off')\n",
    "    axs[c].set_aspect(1/axs[c].get_data_ratio())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled,  epsilon = eps, \n",
    "    startindex = startindex)\n",
    "\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric)[0]\n",
    "indstemp = movetimes1[indstemp]\n",
    "dim_red_spikes_move_scaled = dim_red_spikes_move_scaled[indstemp,:]\n",
    "\n",
    "indstemp = indstemp[:n_points]\n",
    "dim_red_spikes_move_scaled = dim_red_spikes_move_scaled[:n_points,:]\n",
    "\n",
    "d = squareform(pdist(dim_red_spikes_move_scaled[:,:], metric))\n",
    "thresh = np.max(d[~np.isinf(d)])\n",
    "persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)    \n",
    "dgms = persistence['dgms'] \n",
    "plt.figure()\n",
    "plot_diagrams(dgms, list(np.arange(maxdim+1)), lifetime = True)\n",
    "plt.show()\n",
    "plot_barcode(dgms)\n",
    "\n",
    "coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1,], bConsistent = True)\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "for i in range(len(coords_ds)):\n",
    "    ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "for i in range(3):\n",
    "    ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "for i in range(len(coords_ds)):\n",
    "    ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "for i in range(3):\n",
    "    ax[i].set_aspect(1/ax[i].get_data_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords1 = get_coords_all(log_grid_cells, coords_ds_consistent[:,:],   \n",
    "         np.arange(len(log_grid_cells)), indstemp, bPCA = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [0,1]:\n",
    "    fig, axs = plt.subplots(1,1)\n",
    "    mtot, __, __, circ  = binned_statistic_2d(xx[:],\n",
    "                                              yy[:],\n",
    "                                              coords1[:,c], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,1)\n",
    "    costot = gaussian_filter(costot,1)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "    mtot = gaussian_filter(mtot,1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    axs.imshow(mtot)\n",
    "    axs.axis('off')\n",
    "    axs.set_aspect(1/axs.get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.viridis()\n",
    "\n",
    "\n",
    "mcstemp, mtot_all = get_ratemaps_center(coords1, log_grid_cells, numbins = numbins,)\n",
    "num_neurons = len(log_grid_cells[0,:])\n",
    "spk_sim_hex = get_sim(coords1, mcstemp, numbins = numbins, simtype = 'hex', t = 0.2)\n",
    "spk_sim_sqr = get_sim(coords1, mcstemp, numbins = numbins, simtype = 'sqr', t = 0.2)\n",
    "        \n",
    "for i in np.array(np.random.rand(4)*num_neurons, dtype = int):\n",
    "    print(i)\n",
    "    mtot = binned_statistic_2d(xx,yy, log_grid_cells[:,i], bins = 25, statistic = 'mean')[0]\n",
    "    mtot1 = binned_statistic_2d(xx,yy, spk_sim_sqr[:,i], bins = 25, statistic = 'mean')[0]\n",
    "    mtot3 = binned_statistic_2d(xx,yy, spk_sim_hex[:,i], bins = 25, statistic = 'mean')[0]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot,\n",
    "              vmin = 0, \n",
    "              vmax = mtot[~np.isnan(mtot)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_simulated_square.png', transparent = True, pad_inches = 0.1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot1,\n",
    "              vmin = 0, \n",
    "              vmax = mtot1[~np.isnan(mtot1)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_sqr_square.png', transparent = True, pad_inches = 0.1)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot3,\n",
    "              vmin = 0, \n",
    "              vmax = mtot3[~np.isnan(mtot3)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_hex_square.png', transparent = True, pad_inches = 0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mcstemp, mtot_all = get_ratemaps_center(coords1, log_grid_cells, numbins = numbins,)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "plot_centered_ratemaps(coords1, log_grid_cells, mcstemp, numbins, ax)\n",
    "fig.savefig('stacked_ratemap_guanella.png', transparent = True, pad_inches = 0.1)\n",
    "fig.savefig('stacked_ratemap_guanella.pdf', transparent = True, pad_inches = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im = plt.imread('image044.png')\n",
    "im = np.array(im)\n",
    "a1 = np.rot90(im, 1)\n",
    "sp = -np.inf\n",
    "sig = 1\n",
    "\n",
    "cc = np.arctan2(gaussian_filter1d(np.sin(coords1),sigma = sig,axis = 0),\n",
    "               gaussian_filter1d(np.cos(coords1),sigma = sig,axis = 0))%(2*np.pi)\n",
    "bCos = True\n",
    "if bCos:\n",
    "    eps = 0.0001 \n",
    "    digitized = np.concatenate((np.digitize(np.cos(cc[:, 0]), np.linspace(-1-eps,1+eps, len(a1)+1))[:,np.newaxis], \n",
    "                        np.digitize(np.cos(cc[:, 1]), np.linspace(-1-eps,1+eps, len(a1)+1))[:,np.newaxis]),1)\n",
    "else:\n",
    "    digitized = np.concatenate((np.digitize(cc[:, 0], np.linspace(0,2*np.pi, len(a1)+1))[:,np.newaxis], \n",
    "                               np.digitize(cc[:, 1], np.linspace(0,2*np.pi, len(a1)+1))[:,np.newaxis]),1)\n",
    "cc1 = []\n",
    "for i in range(len(digitized)):\n",
    "    cc1.append(a1[digitized[i,1]-1, digitized[i,0]-1]) \n",
    "fig = plt.figure(figsize = (10,5), dpi = 200)\n",
    "plt.axis('off')\n",
    "plt.hsv()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.axis('off')\n",
    "im = ax1.scatter(xx, yy, s = 50, c = cc1, alpha  =0.7)\n",
    "ax1.set_aspect(1/ax1.get_data_ratio())\n",
    "\n",
    "plt.savefig('Guanella_OF_2dcoords', transparent = True, pad_inches = 0.1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.viridis()\n",
    "plt.imshow(log_grid_cells[350,:].reshape(20,20))\n",
    "plt.axis('off')\n",
    "plt.savefig('Pop_vect_guanella.png', transparent = True,pad_inches = 0.1)\n",
    "plt.savefig('Pop_vect_guanella.pdf', transparent = True,pad_inches = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Couey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_torus import *\n",
    "import numpy as np\n",
    "#f = np.load('couey_300random_10ds.npz', allow_pickle = True)\n",
    "#sspikes1  = f['sspikes'].T\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load('/Users/erihe/OneDrive - NTNU/Prosjekt/Toroidal_topology_grid_cell_data/rat_r_day1_grid_modules_1_2_3.npz', \n",
    "            allow_pickle = True)\n",
    "t = f['t']\n",
    "x = f['x']\n",
    "y = f['y']\n",
    "aa = f['azimuth']\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "min_of_1, max_of_1 = 7457, 14778\n",
    "tt, xx, yy, speed, aa = get_pos(x, y, t, aa,\n",
    "                                   min_time = min_of_1, max_time = max_of_1, dt_orig = 0.01, res = 100000)\n",
    "\n",
    "\n",
    "\n",
    "posx = xx[np.arange(0,180000,2)]\n",
    "posy = yy[np.arange(0,180000,2)]\n",
    "post = np.arange(0,180000,2)/100\n",
    "post = post[np.isfinite(posx)]\n",
    "posy = posy[np.isfinite(posx)]\n",
    "posx = posx[np.isfinite(posx)]\n",
    "post = post[np.isfinite(posy)]\n",
    "posx = posx[np.isfinite(posy)]\n",
    "posy = posy[np.isfinite(posy)]\n",
    "post *= 1000\n",
    "\n",
    "side = max(max(posx)-min(posx), max(posy)-min(posy))\n",
    "posx *= 1./side\n",
    "posy *= 1./side\n",
    "posx -= min(posx)\n",
    "posy -= min(posy)\n",
    "\n",
    "tnew = np.arange(0, 599000, 1)\n",
    "posx = np.interp(tnew, post, posx)\n",
    "posy = np.interp(tnew, post, posy)\n",
    "post = tnew\n",
    "\n",
    "#Get angles and velocities\n",
    "angs = np.zeros(len(post))\n",
    "angs[:-1] = np.arctan2(posy[1:]-posy[:-1], posx[1:]-posx[:-1])\n",
    "angs[-1] = angs[-2]\n",
    "speeds = 1000.*np.sqrt((posx[1:]-posx[:-1])**2+(posy[1:]-posy[:-1])**2)\n",
    "nums = len(speeds)\n",
    " \n",
    "numbumps = 4 \n",
    "# parameters of the model\n",
    "extinp = 1.\n",
    "alpha = 0.15\n",
    "ell = 2.\n",
    "inh = -0.02\n",
    "R  = 15.\n",
    "Nx = 28\n",
    "Ny = 44\n",
    "\n",
    "if(numbumps==4):\n",
    "    Nx*=2\n",
    "if(numbumps==8):\n",
    "    Nx*=2\n",
    "    Ny*=2\n",
    "NG=Nx*Ny \n",
    "\n",
    "### MAKE CONNECTIVITY WITH AN OFFSET RELATIVE TO PREFERRED DIRECTION\n",
    "theta = np.zeros([Nx,Ny])\n",
    "theta[0:Nx:2,0:Ny:2] = 0\n",
    "\n",
    "theta[1:Nx:2,0:Ny:2] = 1\n",
    "theta[0:Nx:2,1:Ny:2] = 2\n",
    "theta[1:Nx:2,1:Ny:2] = 3\n",
    "theta = 0.5*np.pi*theta\n",
    "theta = np.ravel(theta)\n",
    "xes = np.zeros([Nx,Ny])\n",
    "yes = np.zeros([Nx,Ny])\n",
    "for x in range(Nx):\n",
    "    for y in range(Ny):\n",
    "        xes[x,y] = x\n",
    "        yes[x,y] = y\n",
    "xes = np.ravel(xes)\n",
    "yes = np.ravel(yes)\n",
    "Rsqrd = R**2\n",
    "W = np.zeros([NG,NG])\n",
    "for xi in range(Nx):\n",
    "    xdiffA = abs(xes-xi-ell*np.cos(theta))\n",
    "    xdiffB = Nx-xdiffA\n",
    "    xdiffA = xdiffA**2\n",
    "    xdiffB = xdiffB**2\n",
    "    for y in range(Ny):\n",
    "        n = xi*Ny+y\n",
    "        ydiffA = abs(yes-y-ell*np.sin(theta))\n",
    "        ydiffB = Ny-ydiffA\n",
    "        ydiffA = ydiffA**2\n",
    "        ydiffB = ydiffB**2\n",
    "        d = xdiffA+ydiffA\n",
    "        W[d<Rsqrd,n] += inh\n",
    "        d = xdiffB+ydiffA\n",
    "        W[d<Rsqrd,n] += inh\n",
    "        d = xdiffA+ydiffB\n",
    "        W[d<Rsqrd,n] += inh\n",
    "        d = xdiffB+ydiffB\n",
    "        W[d<Rsqrd,n] += inh\n",
    "minx = min([min(posy),min(posx)])\n",
    "maxx = max([max(posy),max(posx)])\n",
    "\n",
    "t = 100000\n",
    "posx = posx[np.arange(0, len(posx),10)]\n",
    "posy = posy[np.arange(0, len(posy),10)]\n",
    "xx, yy = posx, posy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xes=0\n",
    "yes=0\n",
    "N = NG\n",
    "\n",
    "S = (np.random.rand(Nx*Ny) > 0.1)*1.0\n",
    "for t in range(2000):\n",
    "    S = S + 0.1*(-S + np.maximum((extinp+np.matmul(S,W)),0.))\n",
    "    S[S<0.00001] = 0.\n",
    "\n",
    "maxS = max(np.ravel(S))\n",
    "minx = min([min(posy),min(posx)])\n",
    "maxx = max([max(posy),max(posx)])\n",
    "whichn = np.arange(len(S))#random.sample(np.arange(len(S)), 100)\n",
    "nodes1 = np.zeros([len(whichn), int(nums/10)])\n",
    "\n",
    "for t in range(0, nums):\n",
    "    S = S + 0.1*(-S + np.maximum((extinp+np.matmul(S,W)+alpha*speeds[t]*np.cos(angs[t]-theta)),0.))\n",
    "    if(np.mod(t,10)==0):\n",
    "        S[S<0.0001] = 0.\n",
    "        nodes1[:,int(t/10)] = S#[]#>0.3*maxS ##some fake spikes\n",
    "    if(np.mod(t,5000)==0 and t>2):\n",
    "        print('%2.2f percent done'%(float(t)*100/float(nums)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.viridis()\n",
    "from scipy.stats import binned_statistic_2d, pearsonr\n",
    "num_neurons = len(nodes1[:,0])\n",
    "inds = np.arange(num_neurons)\n",
    "np.random.shuffle(inds)\n",
    "#for i in inds[:10]:\n",
    "mtot, x_edge, y_edge, circ = binned_statistic_2d(posx[:int(t/10)],\n",
    "                                                 posy[:int(t/10)], \n",
    "                                                 nodes1[80,:], \n",
    "    statistic='mean', bins=50, range=None, expand_binnumbers=True)\n",
    "plt.figure()\n",
    "plt.imshow(mtot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Couey_simulation',  nodes1 = nodes1, posx = posx, posy = posy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load('Couey_simulation.npz', allow_pickle = True)\n",
    "nodes1 = f['nodes1']\n",
    "posx = f['posx']\n",
    "posy = f['posy']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 6         # number of principal components\n",
    "k = 1000          # number of neighbours for downsampling\n",
    "maxdim = 1        # dimension of homology - often just do 1 as it could be expensive (depends on number of points and neighbours)\n",
    "metric = 'cosine' # what metric to use for persistence\n",
    "eps = 0.2        # radial distance downsampling\n",
    "n_points = 1000   # number of downsampled points for persistence analysis \n",
    "\n",
    "\n",
    "spk1 = preprocessing.scale(nodes1.T,axis = 0)\n",
    "dim_red_spikes_move_scaled, e1, e2, var_exp = pca(spk1, dim = dim)\n",
    "\n",
    "dim_red_spikes_move_scaled = np.real(dim_red_spikes_move_scaled)\n",
    "dim_red_spikes_move_scaled /=np.sqrt(np.real(e2[:dim]))\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(var_exp[:15])\n",
    "ax.set_aspect(1/ax.get_data_ratio())\n",
    "fig, axs = plt.subplots(1,dim, figsize= (10,5), dpi = 120)\n",
    "\n",
    "for c in range(dim):\n",
    "    mtot, __, __, circ  = binned_statistic_2d(posx[:len(spk1)],\n",
    "                                              posy[:len(spk1)],\n",
    "                                              dim_red_spikes_move_scaled[:,c], \n",
    "                                              statistic = 'mean', \n",
    "                                              bins = 30,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    mtot[nans] = np.mean(mtot[~nans])\n",
    "    mtot = gaussian_filter(mtot, 1)\n",
    "    plt.viridis()\n",
    "    vals = np.unique(mtot)\n",
    "    mtot[nans] = np.nan\n",
    "    axs[c].imshow(mtot,vmin = vals[int(0.05*len(vals))], vmax = vals[int(0.95*len(vals))])\n",
    "    axs[c].axis('off')\n",
    "    axs[c].set_aspect(1/axs[c].get_data_ratio())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "startindex = np.argmax(np.sum(np.abs(dim_red_spikes_move_scaled),1))\n",
    "movetimes1 = radial_downsampling(dim_red_spikes_move_scaled,  epsilon = eps, \n",
    "    startindex = startindex)\n",
    "\n",
    "indstemp  = sample_denoising(dim_red_spikes_move_scaled[movetimes1,:],  k, \n",
    "                                   n_points, 1, metric)[0]\n",
    "indstemp = movetimes1[indstemp]\n",
    "dim_red_spikes_move_scaled = dim_red_spikes_move_scaled[indstemp,:]\n",
    "\n",
    "indstemp = indstemp[:n_points]\n",
    "dim_red_spikes_move_scaled = dim_red_spikes_move_scaled[:n_points,:]\n",
    "\n",
    "d = squareform(pdist(dim_red_spikes_move_scaled[:,:], metric))\n",
    "thresh = np.max(d[~np.isinf(d)])\n",
    "persistence = ripser(d, maxdim=1, coeff=47, do_cocycles= True, distance_matrix = True, thresh = thresh)    \n",
    "dgms = persistence['dgms'] \n",
    "plt.figure()\n",
    "plot_diagrams(dgms, list(np.arange(maxdim+1)), lifetime = True)\n",
    "plt.show()\n",
    "plot_barcode(dgms)\n",
    "\n",
    "coords_ds, coords_ds_consistent = get_coords_consistent(persistence, coeff = 47, ph_classes = [0,1,], bConsistent = True)\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "for i in range(len(coords_ds)):\n",
    "    ax[i].plot(coords_ds[i,np.argsort(coords_ds[i,:])])\n",
    "ax[2].scatter(*coords_ds[:2,:], s = 100)\n",
    "for i in range(3):\n",
    "    ax[i].set_aspect(1/ax[i].get_data_ratio())\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize = (10,5), dpi = 120)\n",
    "for i in range(len(coords_ds)):\n",
    "    ax[i].plot(coords_ds_consistent[i,np.argsort(coords_ds_consistent[i,:])])\n",
    "ax[2].scatter(*coords_ds_consistent[:2,:], s = 100)\n",
    "for i in range(3):\n",
    "    ax[i].set_aspect(1/ax[i].get_data_ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords1 = get_coords_all(nodes1.T, coords_ds_consistent[:,:],   \n",
    "         np.arange(len(nodes1[0,:])), indstemp, bPCA = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [0,1]:\n",
    "    fig, axs = plt.subplots(1,1)\n",
    "    mtot, __, __, circ  = binned_statistic_2d(posx[:len(spk1)],\n",
    "                                              posy[:len(spk1)],\n",
    "                                              coords1[:,c], \n",
    "                                              statistic = circmean, \n",
    "                                              bins = 50,\n",
    "                                              expand_binnumbers = True)\n",
    "\n",
    "    nans = np.isnan(mtot)\n",
    "    sintot = np.sin(mtot)\n",
    "    costot = np.cos(mtot)\n",
    "    sintot[nans] = np.mean(sintot[~nans])\n",
    "    costot[nans] = np.mean(costot[~nans])\n",
    "    sintot = gaussian_filter(sintot,1)\n",
    "    costot = gaussian_filter(costot,1)\n",
    "    mtot = np.cos(np.arctan2(sintot, costot))\n",
    "    mtot = gaussian_filter(mtot,1)\n",
    "    plt.viridis()\n",
    "    mtot[nans] = np.nan\n",
    "    axs.imshow(mtot)\n",
    "    axs.axis('off')\n",
    "    axs.set_aspect(1/axs.get_data_ratio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx,yy = posx[:len(spk1)], posy[:len(spk1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.viridis()\n",
    "\n",
    "numbins = 12\n",
    "mcstemp, mtot_all = get_ratemaps_center(coords1, nodes1.T, numbins = numbins,)\n",
    "num_neurons = len(nodes1)\n",
    "spk_sim_hex = get_sim(coords1, mcstemp, numbins = numbins, simtype = 'hex', t = 0.2)\n",
    "spk_sim_sqr = get_sim(coords1, mcstemp, numbins = numbins, simtype = 'sqr', t = 0.2)\n",
    "        \n",
    "for i in np.array(np.random.rand(4)*num_neurons, dtype = int):\n",
    "    print(i)\n",
    "    mtot = binned_statistic_2d(xx,yy, nodes1[i,:], bins = 25, statistic = 'mean')[0]\n",
    "    mtot1 = binned_statistic_2d(xx,yy, spk_sim_sqr[:,i], bins = 25, statistic = 'mean')[0]\n",
    "    mtot3 = binned_statistic_2d(xx,yy, spk_sim_hex[:,i], bins = 25, statistic = 'mean')[0]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot,\n",
    "              vmin = 0, \n",
    "              vmax = mtot[~np.isnan(mtot)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_simulated_square.png', transparent = True, pad_inches = 0.1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot1,\n",
    "              vmin = 0, \n",
    "              vmax = mtot1[~np.isnan(mtot1)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_sqr_square.png', transparent = True, pad_inches = 0.1)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mtot3,\n",
    "              vmin = 0, \n",
    "              vmax = mtot3[~np.isnan(mtot3)].max())\n",
    "    ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('ratemap_hex_square.png', transparent = True, pad_inches = 0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "plot_centered_ratemaps(coords1, nodes1.T, mcstemp, numbins, ax)\n",
    "fig.savefig('stacked_ratemap_couey.png', transparent = True, pad_inches = 0.1)\n",
    "fig.savefig('stacked_ratemap_couey.pdf', transparent = True, pad_inches = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im = plt.imread('image044.png')\n",
    "im = np.array(im)\n",
    "a1 = np.rot90(im, 1)\n",
    "sp = -np.inf\n",
    "sig = 1\n",
    "\n",
    "cc = np.arctan2(gaussian_filter1d(np.sin(coords1),sigma = sig,axis = 0),\n",
    "               gaussian_filter1d(np.cos(coords1),sigma = sig,axis = 0))%(2*np.pi)\n",
    "bCos = True\n",
    "if bCos:\n",
    "    eps = 0.0001 \n",
    "    digitized = np.concatenate((np.digitize(np.cos(cc[:, 0]), np.linspace(-1-eps,1+eps, len(a1)+1))[:,np.newaxis], \n",
    "                        np.digitize(np.cos(cc[:, 1]), np.linspace(-1-eps,1+eps, len(a1)+1))[:,np.newaxis]),1)\n",
    "else:\n",
    "    digitized = np.concatenate((np.digitize(cc[:, 0], np.linspace(0,2*np.pi, len(a1)+1))[:,np.newaxis], \n",
    "                               np.digitize(cc[:, 1], np.linspace(0,2*np.pi, len(a1)+1))[:,np.newaxis]),1)\n",
    "cc1 = []\n",
    "for i in range(len(digitized)):\n",
    "    cc1.append(a1[digitized[i,1]-1, digitized[i,0]-1]) \n",
    "fig = plt.figure(figsize = (10,5), dpi = 200)\n",
    "plt.axis('off')\n",
    "plt.hsv()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.axis('off')\n",
    "im = ax1.scatter(xx, yy, s = 50, c = cc1, alpha  =0.7)\n",
    "ax1.set_aspect(1/ax1.get_data_ratio())\n",
    "\n",
    "plt.savefig('Couey_OF_2dcoords', transparent = True, pad_inches = 0.1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "64**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.viridis()\n",
    "plt.imshow(nodes1[:,350].reshape(56,44))\n",
    "plt.axis('off')\n",
    "plt.savefig('Pop_vect_couey.png', transparent = True,pad_inches = 0.1)\n",
    "plt.savefig('Pop_vect_couey.pdf', transparent = True,pad_inches = 0.1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
